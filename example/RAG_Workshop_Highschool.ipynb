{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Workshop: ‡∏™‡∏£‡πâ‡∏≤‡∏á AI ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ ‡∏î‡πâ‡∏ß‡∏¢ RAG Framework\n",
    "### ‡∏î‡∏£. CJ - Walailak University\n",
    "‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏Å‡∏ä‡∏≠‡∏õ‡∏ô‡∏µ‡πâ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏°‡∏±‡∏ò‡∏¢‡∏°‡∏õ‡∏•‡∏≤‡∏¢ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î RAG (Retrieval-Augmented Generation) ‡πÅ‡∏•‡∏∞‡∏•‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö AI ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÑ‡∏î‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install sentence-transformers faiss-cpu openai -q\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "print('‚úÖ ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "text = '''\n",
    "‡∏™‡∏°‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏ã‡∏•‡∏•‡πå‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡∏ô‡∏±‡∏ö‡∏û‡∏±‡∏ô‡∏•‡πâ‡∏≤‡∏ô‡πÄ‡∏ã‡∏•‡∏•‡πå\n",
    "‡∏ã‡∏∂‡πà‡∏á‡∏™‡πà‡∏á‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡πÑ‡∏ü‡∏ü‡πâ‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏Ñ‡∏¥‡∏î ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå ‡πÅ‡∏•‡∏∞‡∏à‡∏î‡∏à‡∏≥‡∏™‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡πÑ‡∏î‡πâ\n",
    "‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡∏™‡∏±‡∏°‡∏ú‡∏±‡∏™ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≤‡∏£‡∏°‡∏≠‡∏á‡πÄ‡∏´‡πá‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ‡∏¢‡∏¥‡∏ô\n",
    "‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡∏ï‡πà‡∏≠‡∏™‡∏¥‡πà‡∏á‡∏£‡∏≠‡∏ö‡∏ï‡∏±‡∏ß‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß\n",
    "'''\n",
    "print('‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£:')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2: ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏¥‡πâ‡∏ô‡πÄ‡∏•‡πá‡∏Å ‡πÜ (Chunking)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "chunk_size = 80\n",
    "chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "print(f'\n‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ä‡∏¥‡πâ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (chunks): {len(chunks)}\n')\n",
    "for i, c in enumerate(chunks):\n",
    "    print(f'Chunk {i+1}: {c}\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3: ‡πÉ‡∏ä‡πâ LLM ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ (‡∏à‡∏≥‡∏•‡∏≠‡∏á Context Generation)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def fake_summary(chunk):\n",
    "    return f'‡∏™‡∏£‡∏∏‡∏õ: {chunk[:30]}...'\n",
    "\n",
    "summaries = [fake_summary(c) for c in chunks]\n",
    "for s in summaries:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¢ ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 4: ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå (Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(summaries)\n",
    "print(f'\nEmbedding ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: {embeddings[0][:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 5: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ (Retriever)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "query = '‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡∏Ñ‡∏¥‡∏î‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£'\n",
    "query_vec = model.encode([query])\n",
    "scores = cosine_similarity(query_vec, embeddings)\n",
    "for i, score in enumerate(scores[0]):\n",
    "    print(f'Chunk {i+1} | ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á: {score:.3f}')\n",
    "\n",
    "best_idx = np.argmax(scores)\n",
    "print('\nüîç ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ñ‡∏∑‡∏≠:')\n",
    "print(chunks[best_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí¨ ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 6: ‡πÉ‡∏´‡πâ AI ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (‡∏à‡∏≥‡∏•‡∏≠‡∏á)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def fake_answer(context, question):\n",
    "    return f'‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {context[:50]}...\n‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: ‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏¥‡∏î‡πÑ‡∏î‡πâ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏™‡∏°‡∏≠‡∏á‡∏°‡∏µ‡πÄ‡∏ã‡∏•‡∏•‡πå‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ó‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Å‡∏±‡∏ô'\n",
    "\n",
    "context = chunks[best_idx]\n",
    "answer = fake_answer(context, query)\n",
    "print('\nü§ñ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á AI:\n', answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéÆ ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 7: ‡πÉ‡∏´‡πâ‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏•‡∏≠‡∏á‡∏ó‡∏≥‡πÄ‡∏≠‡∏á!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "user_q = input('‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì: ')\n",
    "user_vec = model.encode([user_q])\n",
    "scores = cosine_similarity(user_vec, embeddings)\n",
    "best_idx = np.argmax(scores)\n",
    "\n",
    "print('\nüîç ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á:')\n",
    "print(chunks[best_idx])\n",
    "\n",
    "print('\nü§ñ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Ç‡∏≠‡∏á AI:')\n",
    "print(fake_answer(chunks[best_idx], user_q))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "RAG_Workshop_Highschool",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
