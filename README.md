# อบรมเชิงปฏิบัติการ "Large Language Model"

### [01 - ปัญญาประดิษฐ์ (Artificial Intelligence)](01.md)

**ทฤษฎี:**

ปัญญาประดิษฐ์ (Artificial Intelligence: AI) หมายถึง ความสามารถของเครื่องจักรหรือระบบคอมพิวเตอร์ในการ “เลียนแบบ” กระบวนการคิด การเรียนรู้ การตัดสินใจ และการแก้ปัญหาของมนุษย์ โดยมีจุดมุ่งหมายเพื่อให้คอมพิวเตอร์สามารถทำงานที่เดิมต้องใช้สติปัญญาของมนุษย์ เช่น การจดจำเสียง การเข้าใจภาษา การวิเคราะห์ข้อมูลเชิงซ้อน หรือการคาดการณ์แนวโน้มในอนาคตได้อย่างแม่นยำ

AI แบ่งได้เป็น 3 ระดับหลัก ๆ ได้แก่

1. **Artificial Narrow Intelligence (ANI)** — ปัญญาประดิษฐ์เฉพาะด้าน เช่น ระบบแนะนำสินค้า หรือระบบรู้จำใบหน้า
2. **Artificial General Intelligence (AGI)** — ปัญญาประดิษฐ์ที่มีความสามารถเทียบเท่ามนุษย์ในหลากหลายบริบท (ยังอยู่ในขั้นการวิจัย)
3. **Artificial Super Intelligence (ASI)** — ปัญญาประดิษฐ์ที่มีความสามารถเกินกว่ามนุษย์ในทุกด้าน (เป็นแนวคิดเชิงอนาคต)

**หลักวิชาการที่เกี่ยวข้อง:**

* **Machine Learning (ML)** — การสร้างแบบจำลองที่ให้ระบบเรียนรู้จากข้อมูลโดยไม่ต้องเขียนโปรแกรมกำหนดกฎเกณฑ์ตายตัว
* **Deep Learning (DL)** — การใช้โครงข่ายประสาทเทียม (Neural Networks) หลายชั้นในการวิเคราะห์ข้อมูลเชิงลึก เช่น การประมวลผลภาพและเสียง
* **Natural Language Processing (NLP)** — การทำให้เครื่องสามารถเข้าใจและสร้างภาษามนุษย์ได้
* **Computer Vision** — การวิเคราะห์ภาพและวิดีโอเพื่อรับรู้วัตถุและสภาพแวดล้อม
* **Robotics** — การประยุกต์ใช้ AI ในเครื่องจักรกล เพื่อให้สามารถรับรู้และโต้ตอบกับสิ่งแวดล้อมได้อย่างอัตโนมัติ

**แนวคิดเชิงวิชาการเพิ่มเติม:**

AI ยังสัมพันธ์กับศาสตร์อื่น เช่น

* **Cognitive Science** — ศึกษากระบวนการคิดและการเรียนรู้ของมนุษย์ เพื่อนำมาจำลองในระบบ AI
* **Ethics in AI** — ประเด็นด้านจริยธรรม เช่น ความเป็นส่วนตัว ความโปร่งใส และอคติของอัลกอริทึม
* **Human-AI Interaction (HAI)** — การออกแบบการสื่อสารระหว่างมนุษย์กับ AI เพื่อให้เกิดประสิทธิภาพและความเข้าใจร่วมกัน

**ตัวอย่าง:**

* ระบบผู้ช่วยเสียง (Voice Assistant) เช่น Siri, Alexa, หรือ Google Assistant
* ระบบวิเคราะห์ภาพทางการแพทย์ เพื่อช่วยแพทย์วินิจฉัยโรค
* ระบบขับเคลื่อนอัตโนมัติในรถยนต์ (Autonomous Vehicles)
* ระบบตรวจจับการฉ้อโกงทางการเงินด้วย Machine Learning


### [02 - Prompt Engineering](02.md)
**ทฤษฎี:**
Prompt Engineering เป็นศาสตร์ในการออกแบบ “คำสั่ง” หรือข้อความที่ป้อนเข้าไปใน LLM เพื่อให้โมเดลสร้างผลลัพธ์ที่มีคุณภาพและตรงตามความต้องการมากที่สุด แนวคิดนี้พัฒนาขึ้นเพราะ LLM มีความสามารถกว้างมาก หากผู้ใช้ไม่กำหนดชัดเจน คำตอบที่ได้อาจกว้างเกินไป ไม่เจาะจง หรือมีข้อผิดพลาด

**หลักวิชาการที่เกี่ยวข้อง:**

* การสื่อสารกับโมเดลเสมือนการ “ตั้งโจทย์” ที่ต้องระบุเงื่อนไขอย่างครบถ้วน
* เกี่ยวพันกับทฤษฎี *Human-AI Interaction* ที่เน้นว่าผลลัพธ์ของ AI ขึ้นอยู่กับ “การป้อนข้อมูลจากมนุษย์”
* ใช้กลยุทธ์เช่น **Zero-shot prompting** (ไม่มีตัวอย่าง), **Few-shot prompting** (มีตัวอย่างประกอบ), และ **Chain-of-thought prompting** (บังคับให้โมเดลแสดงเหตุผลเป็นลำดับขั้นตอน)

**ตัวอย่าง:**

* “อธิบายการสังเคราะห์แสง” → คำตอบยาว อาจซับซ้อนเกินไป
* “อธิบายการสังเคราะห์แสงสำหรับนักเรียน ม.ปลาย โดยใช้ bullet 3 ข้อ” → คำตอบกระชับและเหมาะกับผู้เรียน

### [03 - การวิเคราะห์ข้อความเชิงสถิติ (Statistical Text Analysis)](03.md)

**ทฤษฎี:**

การวิเคราะห์ข้อความเชิงสถิติ (Statistical Text Analysis) เป็นกระบวนการทางวิทยาศาสตร์ข้อมูล (Data Science) ที่ใช้เทคนิคทางคณิตศาสตร์และสถิติในการสกัดความหมาย โครงสร้าง และรูปแบบจากข้อมูลที่เป็น “ข้อความ” (Text Data) ซึ่งโดยทั่วไปเป็นข้อมูลที่ไม่มีโครงสร้าง (Unstructured Data) เช่น บทความ ข่าว โพสต์ในสื่อสังคมออนไลน์ หรือเอกสารทางวิชาการ

แนวคิดพื้นฐานของการวิเคราะห์ข้อความเชิงสถิติคือการ **แปลงข้อความให้กลายเป็นข้อมูลเชิงตัวเลข (Quantification of Text)** เพื่อให้สามารถนำไปใช้ในการวิเคราะห์เชิงปริมาณได้ เช่น การจำแนกประเภท การจัดกลุ่ม การพยากรณ์ หรือการสร้างแบบจำลองเชิงภาษาศาสตร์

**หลักวิชาการที่เกี่ยวข้อง:**

1. **Text Preprocessing (การเตรียมข้อมูลข้อความ)**

   * การตัดคำ (Tokenization)
   * การลบคำฟุ่มเฟือย (Stopword Removal)
   * การแปลงคำให้อยู่ในรูปมาตรฐาน (Stemming / Lemmatization)
   * การแทนที่สัญลักษณ์ ตัวเลข หรือเครื่องหมายวรรคตอน

2. **Statistical Representation (การแทนค่าข้อความเชิงสถิติ)**

   * **Bag of Words (BoW):** นับจำนวนคำที่ปรากฏโดยไม่สนใจลำดับ
   * **TF-IDF (Term Frequency – Inverse Document Frequency):** วัดความสำคัญของคำในเอกสาร
   * **N-grams:** วิเคราะห์ความสัมพันธ์ของคำต่อเนื่อง เช่น “ปัญญา ประดิษฐ์”

3. **Descriptive Statistics (การวิเคราะห์เชิงพรรณนา)**

   * การนับความถี่ของคำ (Word Frequency Distribution)
   * การวิเคราะห์คำที่พบบ่อยที่สุด (Most Frequent Terms)
   * การสร้างแผนภาพคำ (Word Cloud) เพื่อสรุปแนวโน้มข้อความ

4. **Inferential and Predictive Analysis (การวิเคราะห์เชิงอ้างอิงและพยากรณ์)**

   * **Topic Modeling:** เช่น *Latent Dirichlet Allocation (LDA)* ใช้หาหัวข้อหลักจากข้อความจำนวนมาก
   * **Sentiment Analysis:** วิเคราะห์อารมณ์หรือทัศนคติ เช่น บวก กลาง ลบ
   * **Clustering / Classification:** เช่น การใช้ K-means หรือ Naïve Bayes ในการจัดกลุ่มข้อความ

**แนวคิดเชิงทฤษฎีที่เกี่ยวข้อง:**

* **Corpus Linguistics:** ศาสตร์ที่ศึกษาภาษาโดยใช้คลังข้อมูลขนาดใหญ่ (Corpus)
* **Information Retrieval (IR):** การค้นหาข้อมูลที่เกี่ยวข้องจากข้อความจำนวนมาก
* **Natural Language Processing (NLP):** เป็นรากฐานสำคัญของการวิเคราะห์ข้อความเชิงสถิติ ทั้งในการทำความเข้าใจและสร้างข้อความอัตโนมัติ

**ตัวอย่าง:**

* การวิเคราะห์โพสต์ในโซเชียลมีเดียเพื่อหาความคิดเห็นของประชาชนต่อรัฐบาล
* การตรวจจับหัวข้อสำคัญในข่าวเพื่อวิเคราะห์แนวโน้มทางเศรษฐกิจ
* การวิเคราะห์รีวิวสินค้าเพื่อตรวจสอบความพึงพอใจของลูกค้า
* การใช้ TF-IDF เพื่อคัดเลือกคำสำคัญในบทความวิชาการ


### 04 - การวิเคราะห์ข้อความเชิงบริบทโดยใช้ **Text Embedding**

**ทฤษฎี:**

การวิเคราะห์ข้อความเชิงบริบท (Contextual Text Analysis) เป็นกระบวนการที่มุ่งเน้นการทำความเข้าใจ “ความหมาย” ของข้อความ โดยไม่เพียงพิจารณาคำแต่ละคำแยกกัน แต่คำนึงถึง **บริบท (Context)** ที่คำเหล่านั้นปรากฏร่วมกันด้วย ซึ่งแนวทางสมัยใหม่ได้พัฒนาเทคนิคการแทนข้อความในรูปของ **เวกเตอร์เชิงความหมาย (Semantic Vectors)** ผ่านกระบวนการที่เรียกว่า **Text Embedding**

Text Embedding คือการแปลงข้อความ (เช่น คำ ประโยค หรือเอกสาร) ให้อยู่ในรูปของเวกเตอร์ตัวเลขในมิติสูง (High-dimensional Vector Space) โดยให้เวกเตอร์ของข้อความที่มีความหมายใกล้เคียงกันอยู่ใกล้กันในพื้นที่เวกเตอร์นั้น ซึ่งเป็นการเปิดทางให้ระบบคอมพิวเตอร์สามารถ “เข้าใจ” ความสัมพันธ์เชิงความหมายระหว่างข้อความได้ในเชิงคณิตศาสตร์

**หลักวิชาการที่เกี่ยวข้อง:**

1. **Distributional Semantics Theory (ทฤษฎีความหมายจากการกระจาย)**

   * แนวคิดพื้นฐาน: “คำที่ปรากฏในบริบทใกล้เคียงกันมักมีความหมายคล้ายกัน” (Firth, 1957)
   * เป็นรากฐานทางทฤษฎีของการสร้าง embedding

2. **Vector Space Model (VSM)**

   * การแทนข้อความในรูปของเวกเตอร์
   * ใช้หลักการทางคณิตศาสตร์ เช่น **Cosine Similarity**, **Euclidean Distance** เพื่อวัดความใกล้เคียงของข้อความ

3. **Word Embedding Models (การแทนคำในระดับเวกเตอร์)**

   * **Word2Vec** (Mikolov et al., 2013): เรียนรู้ความสัมพันธ์ของคำจากบริบทในประโยค
   * **GloVe** (Pennington et al., 2014): ใช้สถิติการปรากฏร่วมของคำ (Co-occurrence Statistics)
   * **FastText** (Bojanowski et al., 2016): เพิ่มความสามารถในการจัดการคำใหม่ (Out-of-vocabulary words)

4. **Contextual Embeddings (การแทนข้อความตามบริบท)**

   * พัฒนาโดยใช้โครงข่ายประสาทเทียมเชิงลึก (Deep Neural Networks) เช่น

     * **ELMo (Embeddings from Language Models)**
     * **BERT (Bidirectional Encoder Representations from Transformers)**
     * **GPT / Transformer-based Models**
   * ความโดดเด่น: คำเดียวกันสามารถมีเวกเตอร์ที่แตกต่างกันตามบริบท เช่น คำว่า “bank” หมายถึง “ธนาคาร” หรือ “ริมฝั่งน้ำ” ขึ้นอยู่กับประโยค


**การประยุกต์ใช้ (Applications):**

* **Semantic Search:** การค้นหาข้อความตามความหมายแทนการค้นหาตรงตัว เช่น “รถยนต์ไฟฟ้า” ใกล้เคียงกับ “ยานยนต์พลังงานสะอาด”
* **Clustering / Topic Discovery:** การจัดกลุ่มข้อความที่มีเนื้อหาใกล้เคียงกัน
* **Recommendation Systems:** การแนะนำบทความหรือเอกสารที่มีบริบทสอดคล้องกับความสนใจของผู้ใช้
* **Semantic Similarity Measurement:** การวัดความคล้ายคลึงของข้อความ เช่น ใช้ในระบบตรวจจับการลอกงานหรือการสรุปข้อความ
* **LLM Context Understanding:** ใช้ embedding เป็นส่วนหนึ่งของกระบวนการเรียนรู้เชิงบริบทในโมเดลภาษาขนาดใหญ่ (Large Language Models – LLMs)


**แนวคิดเชิงทฤษฎีเพิ่มเติม:**

* **Manifold Hypothesis:** ข้อความในภาษาธรรมชาติมีโครงสร้างทางความหมายอยู่ในปริภูมิมิติสูงที่ไม่เป็นเชิงเส้น
* **Transfer Learning:** การใช้ embedding ที่ผ่านการฝึกในคลังข้อมูลขนาดใหญ่กับงานใหม่ (เช่น fine-tuning BERT สำหรับการจำแนกอารมณ์)
* **Explainability in Embeddings:** การตีความเชิงความหมายของมิติในเวกเตอร์ เพื่อเข้าใจการตัดสินใจของโมเดล


**ตัวอย่าง:**

* ใช้ BERT Embedding วิเคราะห์ความคล้ายคลึงของข่าวเพื่อจัดกลุ่มข่าวอัตโนมัติ
* ใช้ Sentence Transformers ในการค้นหาข้อความที่เกี่ยวข้องจากฐานข้อมูลเอกสารวิชาการ
* ใช้ Word2Vec วิเคราะห์คำที่มีความหมายใกล้เคียง เช่น “ครู” ใกล้กับ “อาจารย์” และ “ผู้สอน”
* ใช้ OpenAI Embedding Model เพื่อสร้างระบบค้นหาความรู้ (Semantic Search Engine) สำหรับบทความภาษาไทย


### 05 -  Retrieval-Augmented Generation (RAG)
**ทฤษฎี:**
RAG เป็นสถาปัตยกรรมที่พัฒนาขึ้นเพื่อแก้ปัญหา **ข้อจำกัดด้านความรู้** ของ LLM ซึ่งแม้จะถูกฝึกด้วยข้อมูลจำนวนมหาศาล แต่ก็มีขอบเขตตายตัว และอาจล้าสมัยเมื่อเวลาผ่านไป RAG ทำงานโดย “เสริม” LLM ด้วยข้อมูลที่ค้นหาจากฐานข้อมูลหรือเอกสารที่อัปเดตล่าสุด แล้วจึงรวมข้อมูลเหล่านั้นเข้าไปใน Prompt ก่อนสร้างคำตอบ

**หลักวิชาการที่เกี่ยวข้อง:**

* ใช้แนวคิดจาก **Information Retrieval (IR)** ผนวกกับ **Text Generation**
* อาศัยเทคนิค **Vector Embedding + Vector Database** เพื่อค้นหาข้อความที่มีความหมายใกล้เคียงกับคำถาม
* เป็นการแก้ปัญหา *Hallucination* ของ LLM เพราะโมเดลจะอ้างอิงจากข้อมูลจริงที่ถูกดึงเข้ามา

**ตัวอย่าง:**

* ถาม: “ใครเป็นนายกรัฐมนตรีไทยในปัจจุบัน?”

  * LLM ที่ไม่อัปเดตอาจตอบผิด
  * แต่ถ้าใช้ RAG ระบบจะค้นหาข้อมูลจากฐานข่าวสารล่าสุด แล้วให้คำตอบถูกต้อง

### 06 - Fine Tune Model
**ทฤษฎี:**
Fine-tuning คือการ “ฝึกต่อ” (re-train) โมเดลที่มีอยู่แล้ว ด้วยข้อมูลเฉพาะทาง เพื่อให้โมเดลมีความเชี่ยวชาญในโดเมนเฉพาะ หรือเข้าใจบริบททางภาษาและวัฒนธรรมที่แตกต่างจากข้อมูลทั่วไป วิธีนี้ต่างจากการฝึก LLM ตั้งแต่ต้น (training from scratch) ที่ใช้ทรัพยากรสูงมาก Fine-tuning ใช้โมเดลที่มีอยู่แล้วเป็นฐาน (pre-trained model) และเพิ่มความรู้ที่ต้องการลงไป

**หลักวิชาการที่เกี่ยวข้อง:**

* อาศัยแนวคิด **Transfer Learning**: ความรู้จากการฝึกเดิมสามารถถ่ายทอดไปยังงานใหม่ได้
* เทคนิคใหม่ ๆ เช่น **Parameter-Efficient Fine-tuning (PEFT)**, **LoRA (Low-Rank Adaptation)** ช่วยลดภาระในการปรับโมเดล
* ใช้ได้ทั้ง **Supervised Fine-tuning** (ฝึกด้วยข้อมูลที่มีคำตอบกำกับ) และ **Instruction Fine-tuning** (ฝึกให้โมเดลเข้าใจคำสั่งได้ดีขึ้น)

**ตัวอย่าง:**

* โมเดลภาษาอังกฤษทั่วไปอาจไม่เข้าใจบริบทของภาษาไทย
* เมื่อทำ Fine-tuning ด้วยชุดข้อมูลภาษาไทย เช่น บทสนทนาในห้องเรียน → โมเดลจะสื่อสารภาษาไทยได้อย่างถูกต้องและเป็นธรรมชาติมากขึ้น
