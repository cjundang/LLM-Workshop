---
marp: true
title: "From Text to AI Assistant"
theme: default
paginate: true
_class: lead
backgroundImage: url('images/background.jpg')
backgroundSize: cover
backgroundColor: "#ffffff"
color: "#003366"
header: "Assist. Prof. Dr. Chanankorn Jandaeng | Walailak University"
footer: "From Text to AI Assistant"
---

# From Text to AI Assistant Using Machine Learning and RAG Framework
## р╕Бр╕▓р╕гр╕Ыр╕гр╕░р╕бр╕зр╕ер╕Ьр╕ер╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕кр╕╣р╣Ир╕Бр╕▓р╕гр╕кр╕гр╣Йр╕▓р╕Зр╕Ьр╕╣р╣Йр╕Кр╣Ир╕зр╕вр╕нр╕▒р╕Ир╕Йр╕гр╕┤р╕вр╕░р╣Вр╕Фр╕вр╕нр╕▓р╕ир╕▒р╕вр╕Бр╕▓р╕гр╣Ар╕гр╕╡р╕вр╕Щр╕гр╕╣р╣Йр╕Вр╕нр╕Зр╣Ар╕Др╕гр╕╖р╣Ир╕нр╕Зр╣Бр╕ер╕░р╕Бр╕гр╕нр╕Ър╣Бр╕Щр╕зр╕Др╕┤р╕Ф RAG
### 4-6 р╕Хр╕╕р╕ер╕▓р╕Др╕б 2568
### р╕кр╕│р╕Щр╕▒р╕Бр╕зр╕┤р╕Кр╕▓р╕кр╕▓р╕гр╕кр╕Щр╣Ар╕Чр╕ир╕ир╕▓р╕кр╕Хр╕гр╣М р╕бр╕лр╕▓р╕зр╕┤р╕Чр╕вр╕▓р╕ер╕▒р╕вр╕зр╕ер╕▒р╕вр╕ер╕▒р╕Бр╕йр╕Ур╣М

---
# ЁЯдЦ 01-Artificial Ingelligence 
## р╕Ьр╕и. р╕Фр╕г. р╕Кр╕Щр╕▒р╕Щр╕Чр╣Мр╕Бр╕гр╕Ур╣М р╕Ир╕▒р╕Щр╣Бр╕Фр╕З
### р╕кр╕│р╕Щр╕▒р╕Бр╕зр╕┤р╕Кр╕▓р╕кр╕▓р╕гр╕кр╕Щр╣Ар╕Чр╕ир╕ир╕▓р╕кр╕Хр╕гр╣М р╕бр╕лр╕▓р╕зр╕┤р╕Чр╕вр╕▓р╕ер╕▒р╕вр╕зр╕ер╕▒р╕вр╕ер╕▒р╕Бр╕йр╕Ур╣М

---

## 1. р╕Ыр╕▒р╕Нр╕Нр╕▓р╕Ыр╕гр╕░р╕Фр╕┤р╕йр╕Рр╣М (Artificial Intelligence)

**AI р╕Др╕╖р╕нр╕нр╕░р╣Др╕г?**  
р╕Др╕╖р╕нр╕Бр╕▓р╕гр╕Чр╕│р╣Гр╕лр╣Й тАЬр╕Др╕нр╕бр╕Юр╕┤р╕зр╣Ар╕Хр╕нр╕гр╣МтАЭ р╕кр╕▓р╕бр╕▓р╕гр╕Цр╕Чр╕│р╕кр╕┤р╣Ир╕Зр╕Чр╕╡р╣Ир╣Вр╕Фр╕вр╕Ыр╕Бр╕Хр╕┤ **р╕Хр╣Йр╕нр╕Зр╣Гр╕Кр╣Йр╕кр╕Хр╕┤р╕Ыр╕▒р╕Нр╕Нр╕▓р╕Вр╕нр╕Зр╕бр╕Щр╕╕р╕йр╕вр╣М**

р╣Ар╕Кр╣Ир╕Щ  
- р╕Бр╕▓р╕гр╣Ар╕гр╕╡р╕вр╕Щр╕гр╕╣р╣Й (Learning)  
- р╕Бр╕▓р╕гр╣Гр╕лр╣Йр╣Ар╕лр╕Хр╕╕р╕Ьр╕е (Reasoning)  
- р╕Бр╕▓р╕гр╣Бр╕Бр╣Йр╕Ыр╕▒р╕Нр╕лр╕▓ (Problem Solving)  
- р╕Бр╕▓р╕гр╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╕ар╕▓р╕йр╕▓ (Language)

---

### ЁЯФ╣ р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕Зр╣Гр╕Щр╕Кр╕╡р╕зр╕┤р╕Хр╕Ир╕гр╕┤р╕З

- р╕гр╕Цр╕вр╕Щр╕Хр╣Мр╣Др╕гр╣Йр╕Др╕Щр╕Вр╕▒р╕Ъ ЁЯЪЧ  
- Chatbot р╣Бр╕ер╕░р╕Ьр╕╣р╣Йр╕Кр╣Ир╕зр╕вр╣Ар╕кр╕бр╕╖р╕нр╕Щ р╣Ар╕Кр╣Ир╕Щ Siri  
- р╕гр╕░р╕Ър╕Ър╣Бр╕Щр╕░р╕Щр╕│р╕кр╕┤р╕Щр╕Др╣Йр╕▓р╣Гр╕Щ Shopee р╕лр╕гр╕╖р╕н Netflix  

---

### ЁЯФ╣ р╕кр╕гр╕╕р╕Ыр╕кр╕▒р╣Йр╕Щ

> AI р╕Др╕╖р╕нр╕Бр╕▓р╕гр╕Чр╕│р╣Гр╕лр╣Йр╣Ар╕Др╕гр╕╖р╣Ир╕нр╕Зр╕Ир╕▒р╕Бр╕г тАЬр╕Др╕┤р╕Фр╣Бр╕ер╕░р╣Ар╕гр╕╡р╕вр╕Щр╕гр╕╣р╣Йр╣Др╕Фр╣ЙтАЭ р╣Ар╕лр╕бр╕╖р╕нр╕Щр╕бр╕Щр╕╕р╕йр╕вр╣М  
> р╣Ар╕Ыр╣Зр╕Щр╕гр╕▓р╕Бр╕Рр╕▓р╕Щр╕Вр╕нр╕Зр╣Ар╕Чр╕Др╣Вр╕Щр╣Вр╕ер╕вр╕╡р╕кр╕бр╕▒р╕вр╣Гр╕лр╕бр╣Ир╕Чр╕╕р╕Бр╕зр╕▒р╕Щр╕Щр╕╡р╣Й

---

## 2. Machine Learning (ML)

**Machine Learning р╕Др╕╖р╕нр╕нр╕░р╣Др╕г?**  
р╕Бр╕▓р╕гр╕Чр╕│р╣Гр╕лр╣Йр╕Др╕нр╕бр╕Юр╕┤р╕зр╣Ар╕Хр╕нр╕гр╣М тАЬр╣Ар╕гр╕╡р╕вр╕Щр╕гр╕╣р╣Йр╕Ир╕▓р╕Бр╕Вр╣Йр╕нр╕бр╕╣р╕етАЭ р╣Вр╕Фр╕вр╣Др╕бр╣Ир╕Хр╣Йр╕нр╕Зр╕кр╕▒р╣Ир╕Зр╕Чр╕╕р╕Бр╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щ

---

### ЁЯФ╣ р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕Зр╕Чр╕╡р╣Ир╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╕Зр╣Ир╕▓р╕в

- р╕Эр╕╢р╕Бр╣Гр╕лр╣Йр╕Др╕нр╕бр╕Юр╕┤р╕зр╣Ар╕Хр╕нр╕гр╣Мр╕Ир╕│р╣Бр╕Щр╕Б тАЬр╕нр╕╡р╣Ар╕бр╕ер╕Вр╕вр╕░тАЭ  
- р╕кр╕нр╕Щр╕гр╕░р╕Ър╕Ър╣Гр╕лр╣Йр╣Бр╕Щр╕░р╕Щр╕│р╕лр╕Щр╕▒р╕Зр╕Чр╕╡р╣Ир╣Ар╕гр╕▓р╕Кр╕нр╕Ър╕Ър╕Щ Netflix  
- р╣Гр╕Кр╣Йр╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Ар╕Бр╣Ир╕▓р╣Ар╕Юр╕╖р╣Ир╕н тАЬр╕Чр╕│р╕Щр╕▓р╕вр╕вр╕нр╕Фр╕Вр╕▓р╕вр╣Гр╕Щр╕нр╕Щр╕▓р╕Др╕ХтАЭ

---

### ЁЯФ╣ р╕Ыр╕гр╕░р╣Ар╕ар╕Чр╕Вр╕нр╕З Machine Learning

1. **Supervised Learning** тАУ р╕бр╕╡р╕Др╕│р╕Хр╕нр╕Ър╕Бр╕│р╕Бр╕▒р╕Ъ (р╕бр╕╡ label)  
2. **Unsupervised Learning** тАУ р╣Др╕бр╣Ир╕бр╕╡р╕Др╕│р╕Хр╕нр╕Ъ р╣Гр╕лр╣Йр╕Др╣Йр╕Щр╕лр╕▓р╕гр╕╣р╕Ыр╣Бр╕Ър╕Ър╣Ар╕нр╕З  
3. **Reinforcement Learning** тАУ р╣Ар╕гр╕╡р╕вр╕Щр╕гр╕╣р╣Йр╕Ир╕▓р╕Бр╕гр╕▓р╕Зр╕зр╕▒р╕е/р╕Ър╕Чр╕ер╕Зр╣Вр╕Чр╕й  

---

### ЁЯФ╣ р╕кр╕гр╕╕р╕Ыр╕кр╕▒р╣Йр╕Щ

> ML р╕Др╕╖р╕нр╕кр╕░р╕Юр╕▓р╕Щр╣Ар╕Кр╕╖р╣Ир╕нр╕бр╕гр╕░р╕лр╕зр╣Ир╕▓р╕З тАЬр╣Бр╕Щр╕зр╕Др╕┤р╕Фр╕Вр╕нр╕З AIтАЭ  
> р╕Бр╕▒р╕Ъ тАЬр╕Бр╕▓р╕гр╣Гр╕Кр╣Йр╕Зр╕▓р╕Щр╕Ир╕гр╕┤р╕Зр╣Гр╕Щр╕Кр╕╡р╕зр╕┤р╕Хр╕Ыр╕гр╕░р╕Ир╕│р╕зр╕▒р╕ЩтАЭ

---
![w:600px](images/traditional_vs_ML.png)

---
## Machine Learning Process
### 1. Initial Dataset

р╣Ар╕Ыр╣Зр╕Щр╕Ир╕╕р╕Фр╣Ар╕гр╕┤р╣Ир╕бр╕Хр╣Йр╕Щр╕Вр╕нр╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Фр╕┤р╕Ъ (Raw Data) р╕Чр╕╡р╣Ир╕гр╕зр╕Ър╕гр╕зр╕бр╕бр╕▓р╕Ир╕▓р╕Бр╕лр╕ер╕▓р╕вр╣Бр╕лр╕ер╣Ир╕З р╣Ар╕Кр╣Ир╕Щ р╣Др╕Яр╕ер╣М CSV, р╕Рр╕▓р╕Щр╕Вр╣Йр╕нр╕бр╕╣р╕е, р╕лр╕гр╕╖р╕нр╣Ар╕Лр╕Щр╣Ар╕Лр╕нр╕гр╣М р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Щр╕╡р╣Йр╕вр╕▒р╕Зр╣Др╕бр╣Ир╕Юр╕гр╣Йр╕нр╕бр╣Гр╕Кр╣Йр╕Бр╕▒р╕Ър╣Вр╕бр╣Ар╕Фр╕е ML р╣Ар╕Юр╕гр╕▓р╕░р╕нр╕▓р╕Ир╕бр╕╡р╕Др╕зр╕▓р╕бр╕Лр╣Йр╕│р╕Лр╣Йр╕нр╕Щ р╕Ьр╕┤р╕Фр╕Юр╕ер╕▓р╕Ф р╕лр╕гр╕╖р╕нр╣Др╕бр╣Ир╕кр╕бр╕Ър╕╣р╕гр╕Ур╣М
![w:600px](images/ml_process_01.png)

---
### 2. Exploratory Data Analysis (EDA)

р╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щр╕Бр╕▓р╕гр╕кр╕│р╕гр╕зр╕Ир╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Ар╕Юр╕╖р╣Ир╕нр╕Чр╕│р╕Др╕зр╕▓р╕бр╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╣Вр╕Др╕гр╕Зр╕кр╕гр╣Йр╕▓р╕Зр╣Бр╕ер╕░р╕Др╕╕р╕Ур╕ар╕▓р╕Ю р╣Ар╕Кр╣Ир╕Щ

* р╕Бр╕▓р╕гр╕Фр╕╣р╕Бр╕▓р╕гр╕Бр╕гр╕░р╕Ир╕▓р╕вр╕Вр╕нр╕Зр╕Хр╕▒р╕зр╣Бр╕Ыр╕г
* р╕Бр╕▓р╕гр╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ъ outlier
* р╕Бр╕▓р╕гр╣Гр╕Кр╣Йр╣Ар╕Чр╕Др╕Щр╕┤р╕Д **PCA (Principal Component Analysis)** р╣Ар╕Юр╕╖р╣Ир╕нр╕ер╕Фр╕бр╕┤р╕Хр╕┤
* р╕Бр╕▓р╕гр╣Гр╕Кр╣Й **SOM (Self-Organizing Map)** р╣Ар╕Юр╕╖р╣Ир╕нр╕лр╕▓ pattern

![w:600px](images/ml_process_01.png)

---
### 3. Data Cleaning / Pre-processing

р╕Бр╕▓р╕гр╕Чр╕│р╕Др╕зр╕▓р╕бр╕кр╕░р╕нр╕▓р╕Фр╣Бр╕ер╕░р╕Ыр╕гр╕▒р╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Гр╕лр╣Йр╣Ар╕лр╕бр╕▓р╕░р╕кр╕б р╣Ар╕Кр╣Ир╕Щ

* р╕ер╕Ър╕Др╣Ир╕▓р╕Чр╕╡р╣Ир╕Вр╕▓р╕Фр╕лр╕▓р╕вр╣Др╕Ы
* р╣Бр╕Ыр╕ер╕З categorical р╣Ар╕Ыр╣Зр╕Щр╕Хр╕▒р╕зр╣Ар╕ер╕В
* р╕ер╕Ър╕Яр╕╡р╣Ар╕Ир╕нр╕гр╣Мр╕Чр╕╡р╣Ир╕Лр╣Йр╕│р╕Лр╣Йр╕нр╕Щ

![w:600px](images/ml_process_01.png)
---
### 4. Data Splitting

р╣Бр╕Ър╣Ир╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕нр╕Бр╣Ар╕Ыр╣Зр╕Щ 2 р╕кр╣Ир╕зр╕Щр╕лр╕ер╕▒р╕Б:

* **Training Set (80%)** тЖТ р╣Гр╕Кр╣Йр╕кр╕│р╕лр╕гр╕▒р╕Ър╕Эр╕╢р╕Бр╣Вр╕бр╣Ар╕Фр╕е
* **Test Set (20%)** тЖТ р╣Гр╕Кр╣Йр╕кр╕│р╕лр╕гр╕▒р╕Ър╕Ыр╕гр╕░р╣Ар╕бр╕┤р╕Щр╕Ьр╕ер╕ер╕▒р╕Юр╕Шр╣М
![w:600px](images/ml_process_02.png)

---
### 5. Learning Algorithms

р╣Ар╕ер╕╖р╕нр╕Бр╣Вр╕бр╣Ар╕Фр╕ер╕Чр╕╡р╣Ир╣Ар╕лр╕бр╕▓р╕░р╕кр╕б р╣Ар╕Кр╣Ир╕Щ **SVM (Support Vector Machine)**
**DL (Deep Learning)**  **GBM (Gradient Boosting Machine)** **RF (Random Forest)** **kNN (k-Nearest Neighbors)**
![w:600px](images/ml_process_02.png)

---
### 6. Hyperparameter Optimization

р╕Ыр╕гр╕▒р╕Ър╕Др╣Ир╕▓р╕Юр╕▓р╕гр╕▓р╕бр╕┤р╣Ар╕Хр╕нр╕гр╣Мр╕кр╕│р╕Др╕▒р╕Нр╕Вр╕нр╕Зр╣Вр╕бр╣Ар╕Фр╕е р╣Ар╕Кр╣Ир╕Щ р╕Др╣Ир╕▓ k р╕Вр╕нр╕З kNN, р╕Ир╕│р╕Щр╕зр╕Щ tree р╕Вр╕нр╕З Random Forest р╣Ар╕Юр╕╖р╣Ир╕нр╣Ар╕Юр╕┤р╣Ир╕бр╕Ыр╕гр╕░р╕кр╕┤р╕Чр╕Шр╕┤р╕ар╕▓р╕Юр╕Бр╕▓р╕гр╕Чр╕│р╕Щр╕▓р╕в
![w:600px](images/ml_process_02.png)

---
### 7. Feature Selection

р╣Ар╕ер╕╖р╕нр╕Бр╣Ар╕Йр╕Юр╕▓р╕░р╕Др╕╕р╕Ур╕ер╕▒р╕Бр╕йр╕Ур╕░р╕Чр╕╡р╣Ир╕кр╕│р╕Др╕▒р╕Нр╕Чр╕╡р╣Ир╕кр╕╕р╕Ф р╣Ар╕Юр╕╖р╣Ир╕нр╣Гр╕лр╣Йр╣Вр╕бр╣Ар╕Фр╕ер╣Ар╕гр╕╡р╕вр╕Щр╕гр╕╣р╣Йр╣Др╕Фр╣Йр╣Ар╕гр╣Зр╕зр╕Вр╕╢р╣Йр╕Щр╣Бр╕ер╕░р╕ер╕Ф Overfitting
![w:600px](images/ml_process_02.png)

---
### 8. Cross-Validation & Training Model

* р╣Гр╕Кр╣Й **Cross-Validation** р╣Ар╕Юр╕╖р╣Ир╕нр╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ър╕Др╕зр╕▓р╕бр╣Ар╕кр╕Цр╕╡р╕вр╕гр╕Вр╕нр╕Зр╣Вр╕бр╣Ар╕Фр╕е
* р╕Эр╕╢р╕Б (train) р╣Вр╕бр╣Ар╕Фр╕ер╕Ър╕Щ training set р╣Бр╕ер╕░р╣Др╕Фр╣Й **Trained Model**
![w:600px](images/ml_process_03.png)

---
### 9. Evaluate Model Performance

р╕зр╕▒р╕Фр╕Ьр╕ер╕Бр╕▓р╕гр╕Чр╕│р╕Зр╕▓р╕Щр╕Фр╣Йр╕зр╕в metric р╕Чр╕╡р╣Ир╣Ар╕лр╕бр╕▓р╕░р╕кр╕б р╣Ар╕Кр╣Ир╕Щ

* **Classification:** Accuracy, Precision, Recall, F1-score, MCC
* **Regression:** RMSE, MSE, ($R^2$)
![w:600px](images/ml_process_03.png)

---
### 10. Predicted Values

р╕Щр╕│р╣Вр╕бр╣Ар╕Фр╕ер╕Чр╕╡р╣Ир╕Ьр╣Ир╕▓р╕Щр╕Бр╕▓р╕гр╕Ыр╕гр╕░р╣Ар╕бр╕┤р╕Щр╣Бр╕ер╣Йр╕зр╣Др╕Ыр╕Чр╕│р╕Щр╕▓р╕вр╕Др╣Ир╕▓р╕Вр╕нр╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Гр╕лр╕бр╣И

---
 
## 3. Deep Learning (DL)

**Deep Learning р╕Др╕╖р╕нр╕нр╕░р╣Др╕г?**  
р╕Др╕╖р╕нр╕Бр╕▓р╕гр╣Гр╕Кр╣Й **р╣Вр╕Др╕гр╕Зр╕Вр╣Ир╕▓р╕вр╕Ыр╕гр╕░р╕кр╕▓р╕Чр╣Ар╕Чр╕╡р╕вр╕б (Neural Networks)**  
р╕Чр╕╡р╣Ир╣Ар╕ер╕╡р╕вр╕Щр╣Бр╕Ър╕Ър╕Бр╕▓р╕гр╕Чр╕│р╕Зр╕▓р╕Щр╕Вр╕нр╕Зр╕кр╕бр╕нр╕Зр╕бр╕Щр╕╕р╕йр╕вр╣М

---

### ЁЯФ╣ р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕Зр╕Чр╕╡р╣Ир╣Ар╕лр╣Зр╕Щр╕Ър╣Ир╕нр╕в

- р╕Бр╕▓р╕гр╕Ир╕│р╕ар╕▓р╕Юр╣Бр╕бр╕з ЁЯР▒ р╕лр╕гр╕╖р╕нр╕кр╕╕р╕Щр╕▒р╕В ЁЯР╢  
- р╕Бр╕▓р╕гр╕гр╕╣р╣Йр╕Ир╕│р╣Ар╕кр╕╡р╕вр╕Зр╕Юр╕╣р╕Ф (Siri, Google Voice)  
- р╕Бр╕▓р╕гр╕Чр╕│р╕Щр╕▓р╕вр╕гр╕▓р╕Др╕▓р╕лр╕╕р╣Йр╕Щ ЁЯУИ  

---

### ЁЯФ╣ р╕Вр╣Йр╕нр╕Ир╕│р╕Бр╕▒р╕Фр╕Вр╕нр╕З Deep Learning

- р╕Чр╕│р╣Др╕Фр╣Йр╕Фр╕╡р╣Ар╕Йр╕Юр╕▓р╕░ тАЬр╕Зр╕▓р╕Щр╕Чр╕╡р╣Ир╕Эр╕╢р╕Бр╕бр╕▓тАЭ  
- р╣Др╕бр╣Ир╣Ар╕Вр╣Йр╕▓р╣Гр╕И тАЬр╕Др╕зр╕▓р╕бр╕лр╕бр╕▓р╕вр╕Вр╕нр╕Зр╕ар╕▓р╕йр╕▓тАЭ р╕Ир╕гр╕┤р╕З р╣Ж  
- р╕Хр╣Йр╕нр╕Зр╣Гр╕Кр╣Йр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Ир╕│р╕Щр╕зр╕Щр╕бр╕▓р╕Б  

---

### ЁЯФ╣ Key Takeaway

> Deep Learning р╕Др╕╖р╕нр╕гр╕▓р╕Бр╕Рр╕▓р╕Щр╕Вр╕нр╕З AI  
> р╣Бр╕Хр╣Ир╕вр╕▒р╕З тАЬр╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╕ар╕▓р╕йр╕▓тАЭ р╣Др╕Фр╣Йр╣Др╕бр╣Ир╕Фр╕╡р╕Юр╕н  
> р╕Ир╕╢р╕Зр╕Хр╣Йр╕нр╕Зр╕Юр╕▒р╕Тр╕Щр╕▓р╣Др╕Ыр╕кр╕╣р╣И **LLM**

---

## 4. р╕Бр╕▓р╕гр╕Чр╕│р╕Зр╕▓р╕Щр╕Вр╕нр╕З Language Model

### ЁЯФ╣ р╕лр╕ер╕▒р╕Бр╕Бр╕▓р╕гр╕Юр╕╖р╣Йр╕Щр╕Рр╕▓р╕Щ

LLM р╣Ар╕гр╕╡р╕вр╕Щр╕гр╕╣р╣Й **р╕Др╕зр╕▓р╕бр╕Щр╣Ир╕▓р╕Ир╕░р╣Ар╕Ыр╣Зр╕Щр╕Вр╕нр╕Зр╕ер╕│р╕Фр╕▒р╕Ър╕Др╕│**  
р╣Ар╕Юр╕╖р╣Ир╕н тАЬр╕Чр╕│р╕Щр╕▓р╕вр╕Др╕│р╕Цр╕▒р╕Фр╣Др╕ЫтАЭ р╣Гр╕Щр╕Ыр╕гр╕░р╣Вр╕вр╕Д

**р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕З:**  
> тАЬр╕Йр╕▒р╕Щр╕Бр╕│р╕ер╕▒р╕Зр╣Ар╕Вр╕╡р╕вр╕Щ ___тАЭ  
> тЖТ тАЬр╕Ър╕Чр╕Др╕зр╕▓р╕бтАЭ, тАЬр╣Вр╕Ыр╕гр╣Бр╕Бр╕гр╕бтАЭ, тАЬр╕Ир╕Фр╕лр╕бр╕▓р╕втАЭ

---

### ЁЯФ╣ р╕Бр╕▓р╕гр╣Бр╕Ыр╕ер╕Зр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Ар╕Ыр╣Зр╕Щр╕Хр╕▒р╕зр╣Ар╕ер╕В

1. **Tokenization:** р╣Бр╕Ър╣Ир╕Зр╕Др╕│р╣Ар╕Ыр╣Зр╕Щр╕Кр╕┤р╣Йр╕Щр╣Ар╕ер╣Зр╕Б р╣Ж  
   - тАЬр╕кр╕зр╕▒р╕кр╕Фр╕╡р╕Др╕гр╕▒р╕ЪтАЭ тЖТ ["р╕кр╕зр╕▒", "р╕кр╕Фр╕╡", "р╕Др╕гр╕▒р╕Ъ"]  

2. **Embeddings:** р╣Бр╕Ыр╕ер╕Зр╣Бр╕Хр╣Ир╕ер╕░ token р╣Ар╕Ыр╣Зр╕Щр╣Ар╕зр╕Бр╣Ар╕Хр╕нр╕гр╣Мр╕Хр╕▒р╕зр╣Ар╕ер╕В  
   - р╕Чр╕│р╣Гр╕лр╣Йр╣Вр╕бр╣Ар╕Фр╕е тАЬр╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╕Др╕зр╕▓р╕бр╕лр╕бр╕▓р╕втАЭ р╕Вр╕нр╕Зр╕Др╕│р╣Др╕Фр╣Й  

---

## 5. Large Language Model (LLM)

**LLM р╕Др╕╖р╕нр╕нр╕░р╣Др╕г?**  
р╣Вр╕бр╣Ар╕Фр╕е AI р╕Чр╕╡р╣И тАЬр╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╣Бр╕ер╕░р╕кр╕гр╣Йр╕▓р╕Зр╕ар╕▓р╕йр╕▓р╣Др╕Фр╣ЙтАЭ  
р╣Вр╕Фр╕вр╣Гр╕Кр╣Йр╕кр╕Цр╕▓р╕Ыр╕▒р╕Хр╕вр╕Бр╕гр╕гр╕б **Transformer**

---

### ЁЯФ╣ р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕З LLM р╕Чр╕╡р╣Ир╣Ар╕гр╕▓р╕гр╕╣р╣Йр╕Ир╕▒р╕Б

- **ChatGPT** ЁЯза  
- **Google Bard (Gemini)** ЁЯМР  
- **Claude (Anthropic)**  
- **LLaMA (Meta)**  

---

### ЁЯФ╣ р╕Др╕зр╕▓р╕бр╕кр╕▓р╕бр╕▓р╕гр╕Цр╕лр╕ер╕▒р╕Бр╕Вр╕нр╕З LLM

- р╣Ар╕Вр╕╡р╕вр╕Щр╣Бр╕ер╕░р╕кр╕гр╕╕р╕Ыр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕б тЬНя╕П  
- р╣Бр╕Ыр╕ер╕ар╕▓р╕йр╕▓ ЁЯМП  
- р╕Хр╕нр╕Ър╕Др╕│р╕Цр╕▓р╕б ЁЯЧгя╕П  
- р╕кр╕гр╣Йр╕▓р╕Зр╣Вр╕Др╣Йр╕Ф ЁЯТ╗  

---

### ЁЯФ╣ Key Point р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Щр╕▒р╕Бр╣Ар╕гр╕╡р╕вр╕Щ р╕б.р╕Ыр╕ер╕▓р╕в

- LLM тАЬр╕нр╣Ир╕▓р╕Щ-р╣Ар╕Вр╕╡р╕вр╕Щ-р╣Ар╕Вр╣Йр╕▓р╣Гр╕ИтАЭ р╕ар╕▓р╕йр╕▓р╣Ар╕лр╕бр╕╖р╕нр╕Щр╕бр╕Щр╕╕р╕йр╕вр╣М  
- р╣Гр╕Кр╣Й тАЬPromptтАЭ р╕Ър╕нр╕Бр╕кр╕┤р╣Ир╕Зр╕Чр╕╡р╣Ир╕Хр╣Йр╕нр╕Зр╕Бр╕▓р╕г  
- р╕вр╕╖р╕Фр╕лр╕вр╕╕р╣Ир╕Щ р╣Гр╕Кр╣Йр╣Др╕Фр╣Йр╕лр╕ер╕▓р╕вр╕Зр╕▓р╕Щ р╣Вр╕Фр╕вр╣Др╕бр╣Ир╕Хр╣Йр╕нр╕Зр╕кр╕гр╣Йр╕▓р╕Зр╣Гр╕лр╕бр╣И  

---

## 6. LLM р╕Хр╣Ир╕▓р╕Зр╕Ир╕▓р╕Б Deep Learning Model р╕нр╕вр╣Ир╕▓р╕Зр╣Др╕г

| р╕Ыр╕гр╕░р╣Ар╕Фр╣Зр╕Щ | Deep Learning р╕Чр╕▒р╣Ир╕зр╣Др╕Ы | LLM |
|----------|--------------------|-----|
| **р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Эр╕╢р╕Б** | р╣Гр╕Кр╣Йр╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Ар╕Йр╕Юр╕▓р╕░р╕Зр╕▓р╕Щ | р╣Гр╕Кр╣Йр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕бр╕лр╕▓р╕ир╕▓р╕ер╕лр╕ер╕▓р╕вр╕лр╕▒р╕зр╕Вр╣Йр╕н |
| **р╕зр╕▒р╕Хр╕Цр╕╕р╕Ыр╕гр╕░р╕кр╕Зр╕Др╣М** | р╕Зр╕▓р╕Щр╣Ар╕Йр╕Юр╕▓р╕░ р╣Ар╕Кр╣Ир╕Щ р╕Ир╕│р╕ар╕▓р╕Ю | р╕Зр╕▓р╕Щр╕Фр╣Йр╕▓р╕Щр╕ар╕▓р╕йр╕▓р╣Бр╕Ър╕Ър╕Чр╕▒р╣Ир╕зр╣Др╕Ы |
| **р╕Бр╕▓р╕гр╣Ар╕гр╕╡р╕вр╕Щр╕гр╕╣р╣Й** | р╣Ар╕гр╕╡р╕вр╕Щр╕гр╕╣р╣Йр╕Ир╕▓р╕Бр╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕Зр╣Бр╕Др╕Ъ р╣Ж | р╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╣Вр╕Др╕гр╕Зр╕кр╕гр╣Йр╕▓р╕Зр╣Бр╕ер╕░р╕Ър╕гр╕┤р╕Ър╕Чр╕Вр╕нр╕Зр╕ар╕▓р╕йр╕▓ |
| **р╕Др╕зр╕▓р╕бр╕вр╕╖р╕Фр╕лр╕вр╕╕р╣Ир╕Щ** | р╕Хр╣Йр╕нр╕Зр╕Эр╕╢р╕Бр╣Гр╕лр╕бр╣Ир╕Цр╣Йр╕▓р╣Ар╕Ыр╕ер╕╡р╣Ир╕вр╕Щр╕Зр╕▓р╕Щ | р╣Гр╕Кр╣Й Prompt р╣Др╕Фр╣Йр╕лр╕ер╕▓р╕вр╣Бр╕Ър╕Ъ |
| **р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕Зр╣Вр╕бр╣Ар╕Фр╕е** | ResNet, RNN, LSTM | GPT, LLaMA, PaLM |

---

## ЁЯОп р╕кр╕гр╕╕р╕Ыр╕кр╕╕р╕Фр╕Чр╣Йр╕▓р╕в

- AI тЖТ р╣Бр╕Щр╕зр╕Др╕┤р╕Фр╕Бр╕зр╣Йр╕▓р╕З тАЬр╣Гр╕лр╣Йр╣Ар╕Др╕гр╕╖р╣Ир╕нр╕Зр╕Др╕┤р╕Фр╣Др╕Фр╣ЙтАЭ  
- ML тЖТ р╣Гр╕лр╣Йр╣Ар╕Др╕гр╕╖р╣Ир╕нр╕З тАЬр╣Ар╕гр╕╡р╕вр╕Щр╕гр╕╣р╣Йр╕Ир╕▓р╕Бр╕Вр╣Йр╕нр╕бр╕╣р╕етАЭ  
- DL тЖТ р╣Гр╕Кр╣Йр╕кр╕бр╕нр╕Зр╕Ир╕│р╕ер╕нр╕Зр╣Ар╕Юр╕╖р╣Ир╕нр╣Ар╕гр╕╡р╕вр╕Щр╕гр╕╣р╣Йр╕ер╕╢р╕Бр╕Вр╕╢р╣Йр╕Щ  
- LLM тЖТ р╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╕ар╕▓р╕йр╕▓р╣Бр╕ер╕░р╕кр╕гр╣Йр╕▓р╕Зр╕Ыр╕гр╕░р╣Вр╕вр╕Др╣Гр╕лр╕бр╣Ир╣Др╕Фр╣Й  

тЬи р╕Щр╕╡р╣Ир╕Др╕╖р╕нр╣Ар╕лр╕Хр╕╕р╕Ьр╕ер╕Чр╕╡р╣И ChatGPT р╕кр╕▓р╕бр╕▓р╕гр╕Ц тАЬр╕кр╕Щр╕Чр╕Щр╕▓тАЭ р╕Бр╕▒р╕Ър╣Ар╕гр╕▓р╣Др╕Фр╣Йр╣Ар╕лр╕бр╕╖р╕нр╕Щр╕бр╕Щр╕╕р╕йр╕вр╣М тЬи

---

# ЁЯза 02 - р╕Бр╕▓р╕гр╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Ар╕Кр╕┤р╕Зр╕кр╕Цр╕┤р╕Хр╕┤  
### (Statistical Text Analysis)

**Chanankorn**  
*School of Informatics, Walailak University*  

---

## ЁЯФН р╕Ър╕Чр╕Щр╕│р╣Ар╕Кр╕┤р╕Зр╕Чр╕др╕йр╕Ор╕╡

р╕Бр╕▓р╕гр╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Ар╕Кр╕┤р╕Зр╕кр╕Цр╕┤р╕Хр╕┤р╣Ар╕Ыр╣Зр╕Щр╕Бр╕гр╕░р╕Ър╕зр╕Щр╕Бр╕▓р╕гр╕Чр╕▓р╕З  **Data Science** р╣Бр╕ер╕░ **Computational Linguistics**  р╕Чр╕╡р╣Ир╕Щр╕│р╕лр╕ер╕▒р╕Бр╕Бр╕▓р╕гр╕Чр╕▓р╕З **р╕Др╕Ур╕┤р╕Хр╕ир╕▓р╕кр╕Хр╕гр╣Мр╣Бр╕ер╕░р╕кр╕Цр╕┤р╕Хр╕┤**  р╕бр╕▓р╕Ыр╕гр╕░р╕вр╕╕р╕Бр╕Хр╣Мр╕Бр╕▒р╕Ъ **р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Вр╣Йр╕нр╕Др╕зр╕▓р╕б (Text Data)**

ЁЯОп р╣Ар╕Ыр╣Йр╕▓р╕лр╕бр╕▓р╕вр╕лр╕ер╕▒р╕Б:
- р╣Бр╕Ыр╕ер╕Зр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Гр╕лр╣Йр╕нр╕вр╕╣р╣Ир╣Гр╕Щр╕гр╕╣р╕Ыр╣Ар╕Кр╕┤р╕Зр╕Ыр╕гр╕┤р╕бр╕▓р╕У
- р╣Ар╕Юр╕╖р╣Ир╕нр╕Бр╕▓р╕гр╕Ир╕│р╣Бр╕Щр╕Бр╕Ыр╕гр╕░р╣Ар╕ар╕Ч, р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕лр╕▒р╕зр╕Вр╣Йр╕н, р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕нр╕▓р╕гр╕бр╕Ур╣М р╕пр╕ер╕п

---

## 1я╕ПтГг Text Preprocessing  
### (р╕Бр╕▓р╕гр╣Ар╕Хр╕гр╕╡р╕вр╕бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Вр╣Йр╕нр╕Др╕зр╕▓р╕б)

р╣Ар╕Ыр╣Зр╕Щр╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щр╕Юр╕╖р╣Йр╕Щр╕Рр╕▓р╕Щр╕Чр╕╡р╣Ир╕кр╕│р╕Др╕▒р╕Нр╕Чр╕╡р╣Ир╕кр╕╕р╕Ф  
р╣Ар╕Юр╕╖р╣Ир╕нр╕Ир╕▒р╕Фр╕Бр╕▓р╕г **Noise** р╣Ар╕Кр╣Ир╕Щ р╕Др╕│р╕Яр╕╕р╣Ир╕бр╣Ар╕Яр╕╖р╕нр╕вр╕лр╕гр╕╖р╕нр╣Ар╕Др╕гр╕╖р╣Ир╕нр╕Зр╕лр╕бр╕▓р╕вр╕зр╕гр╕гр╕Др╕Хр╕нр╕Щ

---

### ЁЯФ╣ р╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щр╕лр╕ер╕▒р╕Бр╕Вр╕нр╕З Text Preprocessing

1. **Tokenization** тАУ р╕Хр╕▒р╕Фр╕Др╕│  
2. **Stopword Removal** тАУ р╕ер╕Ър╕Др╕│р╕Чр╕╡р╣Ир╣Др╕бр╣Ир╕кр╕│р╕Др╕▒р╕Н  
3. **Stemming / Lemmatization** тАУ р╣Бр╕Ыр╕ер╕Зр╕Др╕│р╣Гр╕лр╣Йр╕нр╕вр╕╣р╣Ир╣Гр╕Щр╕гр╕╣р╕Ыр╕бр╕▓р╕Хр╕гр╕Рр╕▓р╕Щ  
4. **Symbol & Number Removal** тАУ р╕ер╕Ър╕Хр╕▒р╕зр╣Ар╕ер╕Вр╣Бр╕ер╕░р╕кр╕▒р╕Нр╕ер╕▒р╕Бр╕йр╕Ур╣Мр╕Чр╕╡р╣Ир╣Др╕бр╣Ир╕Ир╕│р╣Ар╕Ыр╣Зр╕Щ  

---

### тЬВя╕П Tokenization тАУ р╕Бр╕▓р╕гр╕Хр╕▒р╕Фр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Ар╕Ыр╣Зр╕Щр╕Др╕│

| р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕З | р╕Ьр╕ер╕ер╕▒р╕Юр╕Шр╣Мр╕лр╕ер╕▒р╕З Tokenization |
| -------- | -------------------------- |
| тАЬData scientists are analyzing large amounts of data in 2024!тАЭ | `['Data', 'scientists', 'are', 'analyzing', 'large', ...]` |

ЁЯУШ р╣Бр╕вр╕Бр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Ар╕Ыр╣Зр╕Щр╕Др╕│р╕лр╕гр╕╖р╕нр╕зр╕ер╕╡ р╣Ар╕Юр╕╖р╣Ир╕нр╣Гр╕лр╣Йр╕Щр╕│р╣Др╕Ыр╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╣Ар╕Кр╕┤р╕Зр╕кр╕Цр╕┤р╕Хр╕┤р╣Др╕Фр╣Й

---

### ЁЯЪл Stopword Removal тАУ р╕ер╕Ър╕Др╕│р╕Чр╕╡р╣Ир╣Др╕бр╣Ир╕кр╕│р╕Др╕▒р╕Н

р╕ер╕Ър╕Др╕│р╕Чр╕▒р╣Ир╕зр╣Др╕Ы р╣Ар╕Кр╣Ир╕Щ тАЬtheтАЭ, тАЬofтАЭ, тАЬinтАЭ  

| р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕З | р╕Ьр╕ер╕ер╕▒р╕Юр╕Шр╣М |
| -------- | -------- |
| тАЬData scientists are analyzing large amounts of data in 2024!тАЭ | `['Data', 'scientists', 'analyzing', 'large', 'data']` |

---

### ЁЯФд Lemmatization тАУ р╕Чр╕│р╣Гр╕лр╣Йр╕Др╕│р╕нр╕вр╕╣р╣Ир╣Гр╕Щр╕гр╕╣р╕Ыр╕бр╕▓р╕Хр╕гр╕Рр╕▓р╕Щ

р╕гр╕зр╕бр╕Др╕│р╕Чр╕╡р╣Ир╕бр╕╡р╕гр╕▓р╕Бр╣Ар╕Фр╕╡р╕вр╕зр╕Бр╕▒р╕Щ р╣Ар╕Кр╣Ир╕Щ  
тАЬanalyzingтАЭ тЖТ тАЬanalyzeтАЭ, тАЬmodelsтАЭ тЖТ тАЬmodelтАЭ

---

### ЁЯФг Symbol & Number Removal

р╕ер╕Ър╕Хр╕▒р╕зр╣Ар╕ер╕В р╣Ар╕Др╕гр╕╖р╣Ир╕нр╕Зр╕лр╕бр╕▓р╕в р╣Бр╕ер╕░р╕кр╕▒р╕Нр╕ер╕▒р╕Бр╕йр╕Ур╣Мр╕Чр╕╡р╣Ир╣Др╕бр╣Ир╕Ир╕│р╣Ар╕Ыр╣Зр╕Щ  

ЁЯУН тАЬAI model perform exceptionally well experimentтАЭ

---

### ЁЯзй р╕кр╕гр╕╕р╕Ыр╕ар╕▓р╕Юр╕гр╕зр╕бр╕Бр╕▓р╕гр╣Ар╕Хр╕гр╕╡р╕вр╕бр╕Вр╣Йр╕нр╕бр╕╣р╕е

| р╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щ | р╕зр╕▒р╕Хр╕Цр╕╕р╕Ыр╕гр╕░р╕кр╕Зр╕Др╣М | р╕Ьр╕ер╕ер╕▒р╕Юр╕Шр╣М |
| -------- | ------------- | -------- |
| Tokenization | р╣Бр╕вр╕Бр╕Др╕│ | р╕гр╕▓р╕вр╕Бр╕▓р╕гр╕Др╕│ |
| Stopword Removal | р╕ер╕Ър╕Др╕│р╕Чр╕▒р╣Ир╕зр╣Др╕Ы | р╕ер╕Ф Noise |
| Lemmatization | р╕гр╕зр╕бр╕гр╕╣р╕Ыр╕Др╕│ | р╕Др╕│р╕бр╕▓р╕Хр╕гр╕Рр╕▓р╕Щ |
| Symbol Removal | р╕ер╕Ър╕Хр╕▒р╕зр╣Ар╕ер╕В/р╕кр╕▒р╕Нр╕ер╕▒р╕Бр╕йр╕Ур╣М | р╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕кр╕░р╕нр╕▓р╕Ф |

---

### ЁЯТ╗ р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕Зр╣Вр╕Др╣Йр╕Ф Python

```python
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import string

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

text = "Statistical text analysis involves processing text data."

tokens = word_tokenize(text.lower())
filtered = [w for w in tokens if w not in stopwords.words('english') and w not in string.punctuation]
lemmatizer = WordNetLemmatizer()
lemmatized = [lemmatizer.lemmatize(word) for word in filtered]

print("After Cleaning:", lemmatized)
````

---

## 2я╕ПтГг Statistical Representation

### (р╕Бр╕▓р╕гр╣Бр╕Чр╕Щр╕Др╣Ир╕▓р╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Ар╕Кр╕┤р╕Зр╕кр╕Цр╕┤р╕Хр╕┤)

р╕лр╕ер╕▒р╕Зр╕Ир╕▓р╕Бр╣Ар╕Хр╕гр╕╡р╕вр╕бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Бр╕ер╣Йр╕з тЖТ р╕Хр╣Йр╕нр╕Зр╣Бр╕Чр╕Щр╕Др╣Ир╕▓р╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Ар╕Ыр╣Зр╕Щр╣Ар╕Кр╕┤р╕Зр╕Хр╕▒р╕зр╣Ар╕ер╕В
р╣Ар╕Юр╕╖р╣Ир╕нр╣Гр╕лр╣Йр╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕Чр╕▓р╕Зр╕кр╕Цр╕┤р╕Хр╕┤р╣Др╕Фр╣Й

---

### ЁЯФ╣ Bag of Words (BoW)

**р╣Бр╕Щр╕зр╕Др╕┤р╕Ф:**
р╕Щр╕▒р╕Ър╕Ир╕│р╕Щр╕зр╕Щр╕Др╕│р╕Чр╕╡р╣Ир╕Ыр╕гр╕▓р╕Бр╕Пр╣Гр╕Щр╣Бр╕Хр╣Ир╕ер╕░р╣Ар╕нр╕Бр╕кр╕▓р╕гр╣Вр╕Фр╕вр╣Др╕бр╣Ир╕кр╕Щр╣Гр╕Ир╕ер╕│р╕Фр╕▒р╕Ър╕Др╕│

ЁЯУК р╣Ар╕Кр╣Ир╕Щ
тАЬdata scientist analyze large amount dataтАЭ тЖТ `[data:2, scientist:1, ...]`

тЬЕ р╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╕Зр╣Ир╕▓р╕в
тЪая╕П р╣Др╕бр╣Ир╕кр╕Щр╣Гр╕Ир╕Ър╕гр╕┤р╕Ър╕Чр╕Вр╕нр╕Зр╕Др╕│

---

### ЁЯФ╣ TFтАУIDF (Term Frequency тАУ Inverse Document Frequency)

**р╣Бр╕Щр╕зр╕Др╕┤р╕Ф:**
р╣Гр╕лр╣Йр╕Др╣Ир╕▓р╕Щр╣Йр╕│р╕лр╕Щр╕▒р╕Бр╕Бр╕▒р╕Ър╕Др╕│р╕Чр╕╡р╣Ир╕Ыр╕гр╕▓р╕Бр╕Пр╣Ар╕Йр╕Юр╕▓р╕░р╣Гр╕Щр╕Ър╕▓р╕Зр╣Ар╕нр╕Бр╕кр╕▓р╕г

ЁЯзо р╕кр╕╣р╕Хр╕г:
$TF-IDF(t, d) = TF(t, d) ├Ч log(N / n_t)$

р╕Кр╣Ир╕зр╕вр╣Гр╕лр╣Йр╕Др╕│р╕кр╕│р╕Др╕▒р╕Нр╣Вр╕Фр╕Фр╣Ар╕Фр╣Ир╕Щр╕Вр╕╢р╣Йр╕Щ р╣Ар╕Кр╣Ир╕Щ

* тАЬexperimentтАЭ тЖТ р╕Др╣Ир╕▓р╕кр╕╣р╕З
* тАЬdataтАЭ тЖТ р╕Др╣Ир╕▓р╕Хр╣Ир╕│

---

### ЁЯФ╣ N-grams

**р╣Бр╕Щр╕зр╕Др╕┤р╕Ф:**
р╕Юр╕┤р╕Ир╕▓р╕гр╕Ур╕▓р╕Др╕│р╕Хр╣Ир╕нр╣Ар╕Щр╕╖р╣Ир╕нр╕Зр╕Бр╕▒р╕Щ (sequence of words)

* Unigram тЖТ тАЬmachineтАЭ
* Bigram тЖТ тАЬmachine learningтАЭ
* Trigram тЖТ тАЬmachine learning helpsтАЭ

р╕Кр╣Ир╕зр╕вр╣Гр╕лр╣Йр╕Ир╕▒р╕Ър╕Др╕зр╕▓р╕бр╕лр╕бр╕▓р╕вр╣Бр╕ер╕░р╕Ър╕гр╕┤р╕Ър╕Чр╣Др╕Фр╣Йр╕Фр╕╡р╕Бр╕зр╣Ир╕▓ BoW

---

### ЁЯзй р╕кр╕гр╕╕р╕Ыр╣Ар╕Ыр╕гр╕╡р╕вр╕Ър╣Ар╕Чр╕╡р╕вр╕Ър╣Ар╕Чр╕Др╕Щр╕┤р╕Др╕Бр╕▓р╕гр╣Бр╕Чр╕Щр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕б

| р╣Ар╕Чр╕Др╕Щр╕┤р╕Д  | р╕лр╕ер╕▒р╕Бр╕Бр╕▓р╕г             | р╕Вр╣Йр╕нр╕Фр╕╡       | р╕Вр╣Йр╕нр╕Ир╕│р╕Бр╕▒р╕Ф       |
| ------- | ------------------- | ----------- | -------------- |
| BoW     | р╕Щр╕▒р╕Ър╕Др╕│               | р╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╕Зр╣Ир╕▓р╕в  | р╣Др╕бр╣Ир╕гр╕╣р╣Йр╕ер╕│р╕Фр╕▒р╕Ър╕Др╕│  |
| TFтАУIDF  | р╕Щр╣Йр╕│р╕лр╕Щр╕▒р╕Бр╕Хр╕▓р╕бр╕Др╕зр╕▓р╕бр╕кр╕│р╕Др╕▒р╕Н | р╣Ар╕Щр╣Йр╕Щр╕Др╕│р╕кр╕│р╕Др╕▒р╕Н | р╣Др╕бр╣Ир╕гр╕╣р╣Йр╕Ър╕гр╕┤р╕Ър╕Ч    |
| N-grams | р╕Юр╕┤р╕Ир╕▓р╕гр╕Ур╕▓р╕ер╕│р╕Фр╕▒р╕Ър╕Др╕│      | р╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╕Ър╕гр╕┤р╕Ър╕Ч | р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Вр╕вр╕▓р╕вр╣Гр╕лр╕Нр╣И |

---

## 3я╕ПтГг Descriptive Statistics

### (р╕Бр╕▓р╕гр╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╣Ар╕Кр╕┤р╕Зр╕Юр╕гр╕гр╕Ур╕Щр╕▓)

р╣Гр╕Кр╣Йр╣Ар╕Юр╕╖р╣Ир╕нр╕нр╕Шр╕┤р╕Ър╕▓р╕вр╕ер╕▒р╕Бр╕йр╕Ур╕░р╕Вр╕нр╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Вр╣Йр╕нр╕Др╕зр╕▓р╕б р╣Ар╕Кр╣Ир╕Щ

* р╕Щр╕▒р╕Ър╕Др╕│р╕Чр╕╡р╣Ир╕Юр╕Ър╕Ър╣Ир╕нр╕в
* р╕кр╕гр╣Йр╕▓р╕З **Word Cloud**

---

### ЁЯТ╗ р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕Зр╣Вр╕Др╣Йр╕Ф

```python
from collections import Counter
from wordcloud import WordCloud
import matplotlib.pyplot as plt

words = ["data", "text", "analysis", "data", "machine", "learning"]
freq = Counter(words)
print(freq.most_common(5))

wc = WordCloud(width=800, height=400, background_color='white').generate(" ".join(words))
plt.imshow(wc, interpolation='bilinear')
plt.axis("off")
plt.show()
```

---

## 4я╕ПтГг Inferential & Predictive Analysis

### ЁЯФ╣ Topic Modeling (LDA)

р╣Бр╕вр╕Бр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕нр╕нр╕Бр╣Ар╕Ыр╣Зр╕Щр╕лр╕▒р╕зр╕Вр╣Йр╕нр╣Вр╕Фр╕вр╕нр╕▒р╕Хр╣Вр╕Щр╕бр╕▒р╕Хр╕┤

```python
from sklearn.decomposition import LatentDirichletAllocation
from sklearn.feature_extraction.text import CountVectorizer

docs = ["Machine learning improves analytics.", "Deep learning in AI."]
X = CountVectorizer().fit_transform(docs)
lda = LatentDirichletAllocation(n_components=2).fit(X)
```

---

### ЁЯФ╣ Sentiment Analysis

р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕нр╕▓р╕гр╕бр╕Ур╣Мр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕б р╣Ар╕Кр╣Ир╕Щ р╕Ър╕зр╕Б / р╕Бр╕ер╕▓р╕З / р╕ер╕Ъ

```python
from textblob import TextBlob
texts = ["I love this product!", "Worst experience ever."]
for t in texts:
    print(t, TextBlob(t).sentiment.polarity)
```

---

### ЁЯФ╣ Clustering / Classification

р╣Гр╕Кр╣Й K-means р╕лр╕гр╕╖р╕н Na├пve Bayes
р╣Ар╕Юр╕╖р╣Ир╕нр╕Ир╕▒р╕Фр╕Бр╕ер╕╕р╣Ир╕бр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Вр╕Фр╕вр╕нр╕▒р╕Хр╣Вр╕Щр╕бр╕▒р╕Хр╕┤

```python
from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import TfidfVectorizer
texts = ["AI and ML", "Statistical data science"]
X = TfidfVectorizer().fit_transform(texts)
KMeans(n_clusters=2).fit(X)
```

---

## 5я╕ПтГг р╣Бр╕Щр╕зр╕Др╕┤р╕Фр╣Ар╕Кр╕┤р╕Зр╕Чр╕др╕йр╕Ор╕╡р╕Чр╕╡р╣Ир╣Ар╕Бр╕╡р╣Ир╕вр╕зр╕Вр╣Йр╕нр╕З

| р╕кр╕▓р╕Вр╕▓р╕зр╕┤р╕Кр╕▓                              | р╕Др╕│р╕нр╕Шр╕┤р╕Ър╕▓р╕в                           |
| ------------------------------------- | ---------------------------------- |
| **Corpus Linguistics**                | р╕ир╕╢р╕Бр╕йр╕▓р╕ар╕▓р╕йр╕▓р╣Вр╕Фр╕вр╣Гр╕Кр╣Йр╕Др╕ер╕▒р╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Вр╕Щр╕▓р╕Фр╣Гр╕лр╕Нр╣И  |
| **Information Retrieval (IR)**        | р╕Бр╕▓р╕гр╕Др╣Йр╕Щр╕лр╕▓р╣Бр╕ер╕░р╕Фр╕╢р╕Зр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕Чр╕╡р╣Ир╣Ар╕Бр╕╡р╣Ир╕вр╕зр╕Вр╣Йр╕нр╕З |
| **Natural Language Processing (NLP)** | р╕Бр╕▓р╕гр╕Ыр╕гр╕░р╕бр╕зр╕ер╕Ьр╕ер╣Бр╕ер╕░р╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╕ар╕▓р╕йр╕▓р╕бр╕Щр╕╕р╕йр╕вр╣М     |

---

## 6я╕ПтГг р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕Зр╕Бр╕▓р╕гр╕Ыр╕гр╕░р╕вр╕╕р╕Бр╕Хр╣М

| р╕Бр╕▓р╕гр╕Ыр╕гр╕░р╕вр╕╕р╕Бр╕Хр╣М                | р╕Др╕│р╕нр╕Шр╕┤р╕Ър╕▓р╕в                    |
| -------------------------- | --------------------------- |
| р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╣Вр╕Юр╕кр╕Хр╣Мр╕кр╕▒р╕Зр╕Др╕бр╕нр╕нр╕Щр╣Др╕ер╕Щр╣М | р╕Хр╕гр╕зр╕Ир╕Ир╕▒р╕Ър╕нр╕▓р╕гр╕бр╕Ур╣Мр╕Вр╕нр╕Зр╕Ьр╕╣р╣Йр╣Гр╕Кр╣Й      |
| р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕Вр╣Ир╕▓р╕зр╣Ар╕ир╕гр╕йр╕Рр╕Бр╕┤р╕И      | р╕лр╕▓р╕лр╕▒р╕зр╕Вр╣Йр╕нр╣Бр╕Щр╕зр╣Вр╕Щр╣Йр╕бр╕Ир╕▓р╕Бр╕Ър╕Чр╕Др╕зр╕▓р╕б    |
| р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕гр╕╡р╕зр╕┤р╕зр╕кр╕┤р╕Щр╕Др╣Йр╕▓       | р╕Хр╕гр╕зр╕Ир╕кр╕нр╕Ър╕Др╕зр╕▓р╕бр╕Юр╕╢р╕Зр╕Юр╕нр╣Гр╕Ир╕Вр╕нр╕Зр╕ер╕╣р╕Бр╕Др╣Йр╕▓ |
| р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕Ър╕Чр╕Др╕зр╕▓р╕бр╕зр╕┤р╕Кр╕▓р╕Бр╕▓р╕г     | р╕Фр╕╢р╕Зр╕Др╕│р╕кр╕│р╕Др╕▒р╕Нр╕Фр╣Йр╕зр╕в TF-IDF       |

---

## 7я╕ПтГг р╕Бр╕гр╕Ур╕╡р╕ир╕╢р╕Бр╕йр╕▓: р╕Бр╕▓р╕гр╕Хр╕гр╕зр╕Ир╕Ир╕▒р╕Ъ Spam

р╕Бр╕▓р╕гр╕Ир╕│р╣Бр╕Щр╕Бр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕зр╣Ир╕▓р╣Ар╕Ыр╣Зр╕Щ **Spam / Ham**
р╣Вр╕Фр╕вр╣Гр╕Кр╣Йр╣Ар╕Чр╕Др╕Щр╕┤р╕Д TFтАУIDF р╣Бр╕ер╕░ Na├пve Bayes

---

### ЁЯТ╗ р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕Зр╣Вр╕Др╣Йр╕Фр╕вр╣Ир╕н

```python
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer

X_train, X_test, y_train, y_test = train_test_split(texts, labels)
tfidf = TfidfVectorizer()
X_train_tfidf = tfidf.fit_transform(X_train)

model = MultinomialNB().fit(X_train_tfidf, y_train)
```

---

### ЁЯФО р╕кр╕гр╕╕р╕Ыр╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щр╕Вр╕нр╕З Spam Detection

| р╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щ        | р╕гр╕▓р╕вр╕ер╕░р╣Ар╕нр╕╡р╕вр╕Ф                 |
| -------------- | -------------------------- |
| р╣Вр╕лр╕ер╕Фр╕Вр╣Йр╕нр╕бр╕╣р╕е     | Spam / Ham messages        |
| Preprocessing  | р╕ер╕Ъ stopwords, lowercase    |
| TFтАУIDF         | р╣Бр╕Ыр╕ер╕Зр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Ар╕Ыр╣Зр╕Щр╕Хр╕▒р╕зр╣Ар╕ер╕В      |
| Classification | Na├пve Bayes                |
| Evaluation     | Accuracy, Confusion Matrix |

---

## ЁЯза р╕Бр╕▓р╕гр╕Вр╕вр╕▓р╕вр╣Ар╕Кр╕┤р╕Зр╕зр╕┤р╕Кр╕▓р╕Бр╕▓р╕г

* р╕Чр╕Фр╕ер╕нр╕Зр╣Вр╕бр╣Ар╕Фр╕ер╕нр╕╖р╣Ир╕Щ: Logistic Regression, SVM, Random Forest
* р╣Гр╕Кр╣Й **N-grams** р╣Ар╕Юр╕╖р╣Ир╕нр╣Ар╕Юр╕┤р╣Ир╕бр╕Ър╕гр╕┤р╕Ър╕Ч
* р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣М **Feature Importance**
* р╣Гр╕Кр╣Йр╕Кр╕╕р╕Фр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Ир╕гр╕┤р╕З р╣Ар╕Кр╣Ир╕Щ *Kaggle SMS Spam Dataset*

---

# ЁЯУШ р╕кр╕гр╕╕р╕Ы

* Text Analysis р╕Др╕╖р╕нр╕Бр╕▓р╕гр╣Ар╕Ыр╕ер╕╡р╣Ир╕вр╕Щр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Ар╕Ыр╣Зр╕Щр╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Ар╕Кр╕┤р╕Зр╕Хр╕▒р╕зр╣Ар╕ер╕В
* р╣Гр╕Кр╣Йр╕кр╕Цр╕┤р╕Хр╕┤р╣Бр╕ер╕░ Machine Learning р╣Ар╕Юр╕╖р╣Ир╕нр╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╣Ар╕Щр╕╖р╣Йр╕нр╕лр╕▓
* р╕бр╕╡р╕Бр╕▓р╕гр╕Ыр╕гр╕░р╕вр╕╕р╕Бр╕Хр╣Мр╣Гр╕Кр╣Йр╕Бр╕зр╣Йр╕▓р╕Зр╕Вр╕зр╕▓р╕Зр╣Гр╕Щ Data Science р╣Бр╕ер╕░ NLP

---

# ЁЯУЦ 03 - Contextual Text Analysis
## р╕Ьр╕и. р╕Фр╕г. р╕Кр╕Щр╕▒р╕Щр╕Чр╣Мр╕Бр╕гр╕Ур╣М р╕Ир╕▒р╕Щр╣Бр╕Фр╕З
### р╕кр╕│р╕Щр╕▒р╕Бр╕зр╕┤р╕Кр╕▓р╕кр╕▓р╕гр╕кр╕Щр╣Ар╕Чр╕ир╕ир╕▓р╕кр╕Хр╕гр╣М р╕бр╕лр╕▓р╕зр╕┤р╕Чр╕вр╕▓р╕ер╕▒р╕вр╕зр╕ер╕▒р╕вр╕ер╕▒р╕Бр╕йр╕Ур╣М
---

# ЁЯзн р╕Ър╕Чр╕Щр╕│: р╕Бр╕▓р╕гр╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Ар╕Кр╕┤р╕Зр╕Ър╕гр╕┤р╕Ър╕Ч

**р╣Бр╕Щр╕зр╕Др╕┤р╕Фр╕лр╕ер╕▒р╕Б:**  
р╣Ар╕Вр╣Йр╕▓р╣Гр╕И "р╕Др╕зр╕▓р╕бр╕лр╕бр╕▓р╕вр╕Вр╕нр╕Зр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕б" р╣Вр╕Фр╕вр╕Др╕│р╕Щр╕╢р╕Зр╕Цр╕╢р╕Зр╕Ър╕гр╕┤р╕Ър╕Ч (Context)

> р╕Др╕│р╕зр╣Ир╕▓ тАЬbankтАЭ р╕нр╕▓р╕Ир╕лр╕бр╕▓р╕вр╕Цр╕╢р╕З тАЬр╕Шр╕Щр╕▓р╕Др╕▓р╕гтАЭ р╕лр╕гр╕╖р╕н тАЬр╕гр╕┤р╕бр╕Эр╕▒р╣Ир╕Зр╕Щр╣Йр╕│тАЭ  
> р╕Ър╕гр╕┤р╕Ър╕Чр╕Ир╕╢р╕Зр╕бр╕╡р╕Др╕зр╕▓р╕бр╕кр╕│р╕Др╕▒р╕Нр╕Хр╣Ир╕нр╕Бр╕▓р╕гр╕Хр╕╡р╕Др╕зр╕▓р╕б

---

# тЪЩя╕П Text Embedding р╕Др╕╖р╕нр╕нр╕░р╣Др╕г

**Text Embedding**: р╕Бр╕▓р╕гр╣Бр╕Ыр╕ер╕Зр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Гр╕лр╣Йр╕нр╕вр╕╣р╣Ир╣Гр╕Щр╕гр╕╣р╕Ыр╣Ар╕зр╕Бр╣Ар╕Хр╕нр╕гр╣Мр╕бр╕┤р╕Хр╕┤р╕кр╕╣р╕З  
р╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕Чр╕╡р╣Ир╕бр╕╡р╕Др╕зр╕▓р╕бр╕лр╕бр╕▓р╕вр╕Др╕ер╣Йр╕▓р╕вр╕Бр╕▒р╕Щ тЖТ р╣Ар╕зр╕Бр╣Ар╕Хр╕нр╕гр╣Мр╕нр╕вр╕╣р╣Ир╣Гр╕Бр╕ер╣Йр╕Бр╕▒р╕Щ

- Cosine Similarity тЖТ р╕зр╕▒р╕Фр╕бр╕╕р╕бр╕гр╕░р╕лр╕зр╣Ир╕▓р╕Зр╣Ар╕зр╕Бр╣Ар╕Хр╕нр╕гр╣М  
- Euclidean Distance тЖТ р╕зр╕▒р╕Фр╕гр╕░р╕вр╕░р╕Чр╕▓р╕Зр╕гр╕░р╕лр╕зр╣Ир╕▓р╕Зр╣Ар╕зр╕Бр╣Ар╕Хр╕нр╕гр╣М

> тАЬр╕Др╕гр╕╣тАЭ р╣Гр╕Бр╕ер╣Йр╕Бр╕▒р╕Ъ тАЬр╕нр╕▓р╕Ир╕▓р╕гр╕вр╣МтАЭ р╣Бр╕ер╕░ тАЬр╕Ьр╕╣р╣Йр╕кр╕нр╕ЩтАЭ

---

# ЁЯзй р╕Чр╕др╕йр╕Ор╕╡р╕Юр╕╖р╣Йр╕Щр╕Рр╕▓р╕Щр╕Чр╕▓р╕Зр╕зр╕┤р╕Кр╕▓р╕Бр╕▓р╕г

## Distributional Semantics Theory
> тАЬYou shall know a word by the company it keeps.тАЭ  
(Firth, 1957)

- р╕Др╕│р╕Чр╕╡р╣Ир╕нр╕вр╕╣р╣Ир╣Гр╕Щр╕Ър╕гр╕┤р╕Ър╕Чр╣Ар╕Фр╕╡р╕вр╕зр╕Бр╕▒р╕Щр╕бр╕▒р╕Бр╕бр╕╡р╕Др╕зр╕▓р╕бр╕лр╕бр╕▓р╕вр╕Др╕ер╣Йр╕▓р╕вр╕Бр╕▒р╕Щ
- р╣Ар╕Ыр╣Зр╕Щр╕гр╕▓р╕Бр╕Рр╕▓р╕Щр╕Вр╕нр╕Зр╣Бр╕Щр╕зр╕Др╕┤р╕Фр╕Бр╕▓р╕гр╣Ар╕гр╕╡р╕вр╕Щр╕гр╕╣р╣Йр╣Ар╕Кр╕┤р╕Зр╕Бр╕▓р╕гр╕Бр╕гр╕░р╕Ир╕▓р╕в

---

## Vector Space Model (VSM)

- р╕Бр╕▓р╕гр╣Бр╕Чр╕Щр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Гр╕Щр╕гр╕╣р╕Ыр╣Ар╕зр╕Бр╣Ар╕Хр╕нр╕гр╣М  
- р╕зр╕▒р╕Фр╕Др╕зр╕▓р╕бр╕Др╕ер╣Йр╕▓р╕вр╕Др╕ер╕╢р╕Зр╕Фр╣Йр╕зр╕в cosine / distance  
- р╣Ар╕Ыр╣Зр╕Щр╕Ир╕╕р╕Фр╣Ар╕гр╕┤р╣Ир╕бр╕Хр╣Йр╕Щр╕Вр╕нр╕Зр╣Бр╕Щр╕зр╕Др╕┤р╕Ф Embedding

---

## Word Embedding Models

| р╣Вр╕бр╣Ар╕Фр╕е | р╣Бр╕Щр╕зр╕Др╕┤р╕Ф | р╕Ир╕╕р╕Фр╣Ар╕Фр╣Ир╕Щ |
|-------|--------|---------|
| **Word2Vec** | р╣Ар╕гр╕╡р╕вр╕Щр╕гр╕╣р╣Йр╕Др╕│р╕Ир╕▓р╕Бр╕Ър╕гр╕┤р╕Ър╕Ч | р╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╕Др╕зр╕▓р╕бр╕кр╕▒р╕бр╕Юр╕▒р╕Щр╕Шр╣Мр╣Ар╕Кр╕┤р╕Зр╕Др╕зр╕▓р╕бр╕лр╕бр╕▓р╕в |
| **GloVe** | р╣Гр╕Кр╣Й Co-occurrence Statistics | р╣Ар╕Щр╣Йр╕Щ global context |
| **FastText** | р╣Гр╕Кр╣Й subword | р╕гр╕нр╕Зр╕гр╕▒р╕Ър╕Др╕│р╣Гр╕лр╕бр╣И (OOV words) |

---

## Contextual Embeddings

- р╣Гр╕Кр╣Й Deep Neural Networks (LSTM / Transformer)  
- р╕Др╕│р╣Ар╕Фр╕╡р╕вр╕зр╕Бр╕▒р╕Щр╕бр╕╡р╣Ар╕зр╕Бр╣Ар╕Хр╕нр╕гр╣Мр╕Хр╣Ир╕▓р╕Зр╕Бр╕▒р╕Щр╣Гр╕Щр╕Ър╕гр╕┤р╕Ър╕Чр╕Хр╣Ир╕▓р╕Зр╕Бр╕▒р╕Щ

| р╣Вр╕бр╣Ар╕Фр╕е | р╕ер╕▒р╕Бр╕йр╕Ур╕░ | р╕Ир╕╕р╕Фр╣Ар╕Фр╣Ир╕Щ |
|-------|---------|---------|
| ELMo | Bi-LSTM | р╕Ър╕гр╕┤р╕Ър╕Чр╕кр╕нр╕Зр╕Чр╕┤р╕ир╕Чр╕▓р╕З |
| BERT | Transformer р╕кр╕нр╕Зр╕Чр╕┤р╕ир╕Чр╕▓р╕З | р╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╕Ир╕▓р╕Бр╕Лр╣Йр╕▓р╕в-р╕Вр╕зр╕▓ |
| GPT | Transformer р╣Ар╕Фр╕╡р╕вр╕з | р╕кр╕гр╣Йр╕▓р╕Зр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕Хр╣Ир╕нр╣Ар╕Щр╕╖р╣Ир╕нр╕З |
| SBERT | р╕Ыр╕гр╕▒р╕Ъ BERT р╣Ар╕Юр╕╖р╣Ир╕нр╣Ар╕Ыр╕гр╕╡р╕вр╕Ър╣Ар╕Чр╕╡р╕вр╕Ър╕Ыр╕гр╕░р╣Вр╕вр╕Д | р╣Гр╕Кр╣Йр╣Гр╕Щ Semantic Search |

---

# ЁЯФм р╣Бр╕Щр╕зр╕Др╕┤р╕Фр╕Чр╕др╕йр╕Ор╕╡р╕Вр╕▒р╣Йр╕Щр╕кр╕╣р╕З

## Manifold Hypothesis
- р╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕бр╕╡р╣Вр╕Др╕гр╕Зр╕кр╕гр╣Йр╕▓р╕Зр╕Лр╕▒р╕Ър╕Лр╣Йр╕нр╕Щр╣Гр╕Щр╕бр╕┤р╕Хр╕┤р╕кр╕╣р╕З  
- Embedding р╕Др╕╖р╕нр╕Бр╕▓р╕гр╣Ар╕гр╕╡р╕вр╕Щр╕гр╕╣р╣Йр╣Вр╕Др╕гр╕Зр╕кр╕гр╣Йр╕▓р╕Зр╕ар╕▓р╕вр╣Гр╕Щ (semantic manifold)

## Transfer Learning
- р╣Гр╕Кр╣Й embedding р╕Чр╕╡р╣Ир╕Эр╕╢р╕Бр╕бр╕▓р╕Бр╣Ир╕нр╕Щ р╣Ар╕Кр╣Ир╕Щ BERT, GloVe  
- р╕Щр╕│р╣Др╕Ыр╣Гр╕Кр╣Й fine-tuning р╣Гр╕Щр╕Зр╕▓р╕Щр╣Гр╕лр╕бр╣И (р╣Ар╕Кр╣Ир╕Щ Sentiment Analysis)

## Explainability
- р╕Юр╕вр╕▓р╕вр╕▓р╕бр╕Хр╕╡р╕Др╕зр╕▓р╕бр╣Бр╕Бр╕Щр╕Вр╕нр╕Зр╣Ар╕зр╕Бр╣Ар╕Хр╕нр╕гр╣М р╣Ар╕Кр╣Ир╕Щ р╣Ар╕Юр╕и, р╕нр╕▓р╕гр╕бр╕Ур╣М

---

# ЁЯТ╝ р╕Бр╕▓р╕гр╕Ыр╕гр╕░р╕вр╕╕р╕Бр╕Хр╣Мр╣Гр╕Кр╣Й Text Embedding

| р╕Бр╕▓р╕гр╕Ыр╕гр╕░р╕вр╕╕р╕Бр╕Хр╣М | р╕Др╕│р╕нр╕Шр╕┤р╕Ър╕▓р╕в |
|--------------|----------|
| Semantic Search | р╕Др╣Йр╕Щр╕лр╕▓р╕Хр╕▓р╕бр╕Др╕зр╕▓р╕бр╕лр╕бр╕▓р╕вр╣Бр╕Чр╕Щр╕Бр╕▓р╕гр╕Др╣Йр╕Щр╕лр╕▓р╕Др╕│р╕Хр╕гр╕Зр╕Хр╕▒р╕з |
| Clustering | р╕Ир╕▒р╕Фр╕Бр╕ер╕╕р╣Ир╕бр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Гр╕Бр╕ер╣Йр╣Ар╕Др╕╡р╕вр╕З |
| Recommendation | р╣Бр╕Щр╕░р╕Щр╕│р╣Ар╕Щр╕╖р╣Йр╕нр╕лр╕▓р╕Др╕ер╣Йр╕▓р╕вр╕Бр╕▒р╕Щ |
| Similarity Measurement | р╕Хр╕гр╕зр╕Ир╕Ир╕▒р╕Ър╕Бр╕▓р╕гр╕ер╕нр╕Бр╕Зр╕▓р╕Щ / р╕Др╕зр╕▓р╕бр╣Ар╕лр╕бр╕╖р╕нр╕Щр╕Вр╕нр╕Зр╕Ыр╕гр╕░р╣Вр╕вр╕Д |
| LLM Understanding | р╣Гр╕Кр╣Йр╣Гр╕Щ GPT, BERT, Claude р╕пр╕ер╕п |

---

# ЁЯза р╕кр╕гр╕╕р╕Ыр╣Ар╕Кр╕┤р╕Зр╕Чр╕др╕йр╕Ор╕╡

1. Embedding = р╕кр╕░р╕Юр╕▓р╕Щр╕гр╕░р╕лр╕зр╣Ир╕▓р╕Зр╕ар╕▓р╕йр╕▓р╣Бр╕ер╕░р╕Др╕Ур╕┤р╕Хр╕ир╕▓р╕кр╕Хр╕гр╣М  
2. Contextual Embedding = р╕зр╕┤р╕зр╕▒р╕Тр╕Щр╕▓р╕Бр╕▓р╕гр╕Вр╕▒р╣Йр╕Щр╕кр╕╣р╕Зр╕Вр╕нр╕З NLP  
3. р╣Ар╕Ыр╣Зр╕Щр╕гр╕▓р╕Бр╕Рр╕▓р╕Щр╕Вр╕нр╕Зр╕гр╕░р╕Ър╕Ъ Search, Chatbot, р╣Бр╕ер╕░ LLMs

---

# ЁЯзк Workshop: Text Embedding

**р╕зр╕▒р╕Хр╕Цр╕╕р╕Ыр╕гр╕░р╕кр╕Зр╕Др╣М**  
- р╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╕Бр╕▓р╕гр╣Бр╕Ыр╕ер╕Зр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Ар╕Ыр╣Зр╕Щр╣Ар╕зр╕Бр╣Ар╕Хр╕нр╕гр╣М  
- р╕зр╕▒р╕Фр╕Др╕зр╕▓р╕бр╕Др╕ер╣Йр╕▓р╕вр╕Др╕ер╕╢р╕Зр╣Ар╕Кр╕┤р╕Зр╕Др╕зр╕▓р╕бр╕лр╕бр╕▓р╕в  
- р╣Ар╕Ыр╕гр╕╡р╕вр╕Ър╣Ар╕Чр╕╡р╕вр╕Ъ Keyword vs Contextual Approach

---

## ЁЯФз р╣Ар╕Др╕гр╕╖р╣Ир╕нр╕Зр╕бр╕╖р╕нр╣Бр╕ер╕░р╕Вр╣Йр╕нр╕бр╕╣р╕е

- Python / Google Colab  
- Libraries: `sentence-transformers`, `numpy`, `sklearn`

```python
texts = [
 "р╕гр╕Цр╕вр╕Щр╕Хр╣Мр╣Др╕Яр╕Яр╣Йр╕▓р╣Ар╕Ыр╣Зр╕Щр╕бр╕┤р╕Хр╕гр╕Хр╣Ир╕нр╕кр╕┤р╣Ир╕Зр╣Бр╕зр╕Фр╕ер╣Йр╕нр╕б",
 "р╕вр╕▓р╕Щр╕вр╕Щр╕Хр╣Мр╕Юр╕ер╕▒р╕Зр╕Зр╕▓р╕Щр╕кр╕░р╕нр╕▓р╕Фр╕Бр╕│р╕ер╕▒р╕Зр╣Др╕Фр╣Йр╕гр╕▒р╕Ър╕Др╕зр╕▓р╕бр╕Щр╕┤р╕вр╕б",
 "р╕Шр╕Щр╕▓р╕Др╕▓р╕гр╣Гр╕лр╣Йр╕Ър╕гр╕┤р╕Бр╕▓р╕гр╕кр╕┤р╕Щр╣Ар╕Кр╕╖р╣Ир╕нр╕Ър╣Йр╕▓р╕Щ",
 "р╣Бр╕бр╣Ир╕Щр╣Йр╕│р╕бр╕╡р╕Щр╣Йр╕│р╕бр╕▓р╕Бр╣Гр╕Щр╕др╕Фр╕╣р╕Эр╕Щ"
]
```

---

## ЁЯза р╕кр╕гр╣Йр╕▓р╕З Sentence Embeddings

```python
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
embeddings = model.encode(texts)
```

- р╕Вр╣Йр╕нр╕Др╕зр╕▓р╕б тЖТ р╣Ар╕зр╕Бр╣Ар╕Хр╕нр╕гр╣Мр╕бр╕┤р╕Хр╕┤ 384  
- р╕Др╕зр╕▓р╕бр╕лр╕бр╕▓р╕вр╣Гр╕Бр╕ер╣Йр╕Бр╕▒р╕Щ тЖТ р╣Ар╕зр╕Бр╣Ар╕Хр╕нр╕гр╣Мр╕нр╕вр╕╣р╣Ир╣Гр╕Бр╕ер╣Йр╕Бр╕▒р╕Щ

---

## ЁЯУП Semantic Similarity

```python
from sentence_transformers import util
similarity = util.cos_sim(embeddings, embeddings)
```

| р╕Др╣Ир╕▓ | р╕Бр╕▓р╕гр╕Хр╕╡р╕Др╕зр╕▓р╕б |
|------|-------------|
| 0.8тАУ1.0 | р╕Др╕ер╣Йр╕▓р╕вр╕Бр╕▒р╕Щр╕бр╕▓р╕Б |
| 0.5тАУ0.8 | р╕Др╣Ир╕нр╕Щр╕Вр╣Йр╕▓р╕Зр╕Др╕ер╣Йр╕▓р╕в |
| <0.2 | р╕Хр╣Ир╕▓р╕Зр╕Бр╕▒р╕Щр╕бр╕▓р╕Б |

---

# ЁЯУК Visualization

```python
from sklearn.manifold import TSNE
plt.scatter(...)
```

- р╕Ир╕╕р╕Фр╣Гр╕Бр╕ер╣Йр╕Бр╕▒р╕Щ тЖТ р╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕Др╕ер╣Йр╕▓р╕вр╕Бр╕▒р╕Щ  
- р╣Бр╕кр╕Фр╕З semantic clusters

---

# ЁЯзк Showcase: Spam Detection

**р╣Бр╕Щр╕зр╕Др╕┤р╕Ф:**  
р╣Бр╕вр╕Бр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Ар╕Ыр╣Зр╕Щ 2 р╕Бр╕ер╕╕р╣Ир╕б тАФ Spam vs Ham  
р╣Гр╕Кр╣Й Contextual Embedding + KNN Classifier

```python
data = {...}
model = SentenceTransformer('all-MiniLM-L6-v2')
embeddings = model.encode(data['text'])
```

---

## ЁЯФН р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕Зр╕Ьр╕ер╕ер╕▒р╕Юр╕Шр╣М

| р╕Вр╣Йр╕нр╕Др╕зр╕▓р╕б | р╕Ьр╕ер╕ер╕▒р╕Юр╕Шр╣М |
|-----------|----------|
| тАЬGet rich quick!тАЭ | spam |
| тАЬReview project report.тАЭ | ham |

**Embedding р╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╣Ар╕Ир╕Хр╕Щр╕▓ (intent)** р╣Бр╕бр╣Йр╣Др╕бр╣Ир╕бр╕╡ keyword тАЬspamтАЭ

---

# ЁЯза Key Insights

- Context р╕кр╕│р╕Др╕▒р╕Нр╕Бр╕зр╣Ир╕▓р╕Др╕│р╣Ар╕Фр╕╡р╣Ир╕вр╕з  
- Embedding р╕Кр╣Ир╕зр╕вр╣Гр╕лр╣Йр╕Др╕нр╕бр╕Юр╕┤р╕зр╣Ар╕Хр╕нр╕гр╣Мр╣Ар╕Вр╣Йр╕▓р╣Гр╕И тАЬр╕Др╕зр╕▓р╕бр╕лр╕бр╕▓р╕втАЭ  
- р╣Гр╕Кр╣Йр╣Др╕Фр╣Йр╕Чр╕▒р╣Йр╕Зр╣Гр╕Щр╕Зр╕▓р╕Щ Search, Chatbot, р╣Бр╕ер╕░ AI Model  
- р╣Ар╕Ыр╣Зр╕Щр╕гр╕▓р╕Бр╕Рр╕▓р╕Щр╕Вр╕нр╕З LLM р╕Чр╕╕р╕Бр╕Кр╕Щр╕┤р╕Ф

---

# ЁЯдЦ Workshop:  
**04-р╕кр╕гр╣Йр╕▓р╕З AI р╕Хр╕нр╕Ър╕Др╕│р╕Цр╕▓р╕бр╕Ир╕▓р╕Бр╣Ар╕нр╕Бр╕кр╕▓р╕г (Document Q&A)**  
р╕Фр╣Йр╕зр╕вр╣Бр╕Щр╕зр╕Др╕┤р╕Ф **RAG Framework**

ЁЯСитАНЁЯПл р╕Ьр╕╣р╣Йр╕кр╕нр╕Щ: р╕Фр╕г. CJ  
Walailak University  

---

# ЁЯОп р╣Ар╕Ыр╣Йр╕▓р╕лр╕бр╕▓р╕вр╕Вр╕нр╕З Workshop

- р╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╕зр╣Ир╕▓ **AI р╕нр╣Ир╕▓р╕Щр╣Бр╕ер╕░р╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╣Ар╕нр╕Бр╕кр╕▓р╕гр╣Др╕Фр╣Йр╕нр╕вр╣Ир╕▓р╕Зр╣Др╕г**  
- р╕гр╕╣р╣Йр╕Ир╕▒р╕Бр╣Бр╕Щр╕зр╕Др╕┤р╕Ф **RAG тАУ Retrieval Augmented Generation**  
- р╣Др╕Фр╣Йр╕ер╕нр╕З **р╕кр╕гр╣Йр╕▓р╕Зр╕гр╕░р╕Ър╕Ър╕Цр╕▓р╕б-р╕Хр╕нр╕Ър╕Ир╕▓р╕Бр╣Ар╕нр╕Бр╕кр╕▓р╕гр╕Ир╕гр╕┤р╕З**  
- р╕кр╕гр╣Йр╕▓р╕З **Chatbot р╕Ьр╕╣р╣Йр╕Кр╣Ир╕зр╕вр╕нр╣Ир╕▓р╕Щр╕лр╕Щр╕▒р╕Зр╕кр╕╖р╕н** р╕Фр╣Йр╕зр╕вр╕Хр╕▒р╕зр╣Ар╕нр╕З

---

# ЁЯза р╕Ыр╕▒р╕Нр╕лр╕▓р╕Чр╕╡р╣Ир╣Ар╕гр╕▓р╕Юр╕Ъ

> тАЬр╕нр╕вр╕▓р╕Бр╕гр╕╣р╣Йр╣Гр╕Ир╕Др╕зр╕▓р╕бр╕кр╕│р╕Др╕▒р╕Нр╕Вр╕нр╕Зр╕Ър╕Чр╕Др╕зр╕▓р╕б р╣Бр╕Хр╣Ир╣Др╕бр╣Ир╕нр╕вр╕▓р╕Бр╕нр╣Ир╕▓р╕Щр╕Чр╕▒р╣Йр╕Зр╕лр╕бр╕Ф!тАЭ

AI р╕кр╕▓р╕бр╕▓р╕гр╕Цр╕Кр╣Ир╕зр╕вр╣Ар╕гр╕▓р╣Др╕Фр╣Йр╣Вр╕Фр╕в...

1. р╕нр╣Ир╕▓р╕Щр╣Ар╕нр╕Бр╕кр╕▓р╕гр╣Бр╕Чр╕Щр╣Ар╕гр╕▓  
2. р╕Др╣Йр╕Щр╕лр╕▓р╕кр╣Ир╕зр╕Щр╕кр╕│р╕Др╕▒р╕Н  
3. р╕Хр╕нр╕Ър╕Др╕│р╕Цр╕▓р╕бр╕Ир╕▓р╕Бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Ир╕гр╕┤р╕З

---

# ЁЯФН р╣Бр╕Щр╕зр╕Др╕┤р╕Фр╕Вр╕нр╕З RAG

**RAG = Retrieval + Augmented + Generation**

| р╕кр╣Ир╕зр╕Щ | р╕лр╕Щр╣Йр╕▓р╕Чр╕╡р╣И |
|------|----------|
| Retrieval | р╕Др╣Йр╕Щр╕лр╕▓р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Ир╕▓р╕Бр╣Ар╕нр╕Бр╕кр╕▓р╕г |
| Augmented | р╣Ар╕кр╕гр╕┤р╕бр╕Ър╕гр╕┤р╕Ър╕Чр╣Гр╕лр╣Й AI р╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╣Ар╕Щр╕╖р╣Йр╕нр╕лр╕▓ |
| Generation | р╕кр╕гр╣Йр╕▓р╕Зр╕Др╕│р╕Хр╕нр╕Ър╕Фр╣Йр╕зр╕вр╕ар╕▓р╕йр╕▓р╕Чр╕╡р╣Ир╕бр╕Щр╕╕р╕йр╕вр╣Мр╣Ар╕Вр╣Йр╕▓р╣Гр╕И |

---

# ЁЯТб р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕Зр╣Гр╕Щр╕Кр╕╡р╕зр╕┤р╕Хр╕Ир╕гр╕┤р╕З

> р╕Цр╣Йр╕▓р╣Ар╕гр╕▓р╕Цр╕▓р╕бр╣Ар╕Юр╕╖р╣Ир╕нр╕Щр╕зр╣Ир╕▓  
> тАЬр╕Ър╕Чр╕Чр╕╡р╣И 3 р╕зр╕┤р╕Чр╕вр╕▓р╕ир╕▓р╕кр╕Хр╕гр╣М р╕Юр╕╣р╕Фр╕Цр╕╢р╕Зр╕нр╕░р╣Др╕гр╕Щр╕░?тАЭ

р╣Ар╕Юр╕╖р╣Ир╕нр╕Щр╕Ир╕░р╣Др╕Ыр╣Ар╕Ыр╕┤р╕Фр╕лр╕Щр╕▒р╕Зр╕кр╕╖р╕н  
тЖТ р╕нр╣Ир╕▓р╕Щр╕Ър╕▓р╕Зр╕вр╣Ир╕нр╕лр╕Щр╣Йр╕▓  
тЖТ р╣Бр╕ер╣Йр╕зр╕кр╕гр╕╕р╕Ыр╕Хр╕нр╕Ър╣Гр╕лр╣Йр╣Ар╕гр╕▓р╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╕Зр╣Ир╕▓р╕в

ЁЯУШ р╕Щр╕▒р╣Ир╕Щр╣Бр╕лр╕ер╕░! р╕Др╕╖р╕нр╕лр╕ер╕▒р╕Бр╕Бр╕▓р╕гр╕Вр╕нр╕З **RAG Framework**

---

# тЪЩя╕П р╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щр╕Вр╕нр╕Зр╕гр╕░р╕Ър╕Ъ RAG

1. ЁЯУД **р╣Бр╕Ър╣Ир╕Зр╣Ар╕нр╕Бр╕кр╕▓р╕гр╣Ар╕Ыр╣Зр╕Щр╕Кр╕┤р╣Йр╕Щр╣Ар╕ер╣Зр╕Б р╣Ж (Chunking)**  
2. ЁЯза **р╣Гр╕лр╣Й AI р╕кр╕гр╕╕р╕Ыр╣Бр╕Хр╣Ир╕ер╕░р╕кр╣Ир╕зр╕Щ (Context)**  
3. ЁЯФв **р╣Бр╕Ыр╕ер╕Зр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Ар╕Ыр╣Зр╕Щр╕Хр╕▒р╕зр╣Ар╕ер╕В (Embedding)**  
4. ЁЯФН **р╕Др╣Йр╕Щр╕лр╕▓р╕кр╣Ир╕зр╕Щр╕Чр╕╡р╣Ир╣Ар╕Бр╕╡р╣Ир╕вр╕зр╕Вр╣Йр╕нр╕З (Retriever)**  
5. ЁЯТм **р╕кр╕гр╣Йр╕▓р╕Зр╕Др╕│р╕Хр╕нр╕Ър╕Ир╕▓р╕Бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Ир╕гр╕┤р╕З (Generative Model)**  

---

# ЁЯзй р╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щр╕Чр╕╡р╣И 1: Chunking

AI р╣Др╕бр╣Ир╕кр╕▓р╕бр╕▓р╕гр╕Цр╕нр╣Ир╕▓р╕Щр╕Чр╕▒р╣Йр╕Зр╣Ар╕ер╣Ир╕бр╣Др╕Фр╣Й  
р╣Ар╕гр╕▓р╕Хр╣Йр╕нр╕З тАЬр╕лр╕▒р╣Ир╕ЩтАЭ р╣Ар╕нр╕Бр╕кр╕▓р╕гр╣Гр╕лр╣Йр╣Ар╕Ыр╣Зр╕Щр╕кр╣Ир╕зр╕Щр╕вр╣Ир╕нр╕в р╣Ж

```python
text = "р╕кр╕бр╕нр╕Зр╕Вр╕нр╕Зр╕бр╕Щр╕╕р╕йр╕вр╣Мр╕бр╕╡р╣Ар╕Лр╕ер╕ер╣Мр╕Ыр╕гр╕░р╕кр╕▓р╕Чр╕бр╕▓р╕Бр╕бр╕▓р╕в..."
chunks = [text[i:i+50] for i in range(0, len(text), 50)]
print(chunks)
````

ЁЯУШ *р╕Чр╕│р╣Гр╕лр╣Й AI р╕вр╣Ир╕нр╕вр╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Др╕Фр╣Йр╕Зр╣Ир╕▓р╕вр╕Вр╕╢р╣Йр╕Щ*

---

# ЁЯза р╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щр╕Чр╕╡р╣И 2: р╕кр╕гр╣Йр╕▓р╕Зр╕Ър╕гр╕┤р╕Ър╕Чр╕Фр╣Йр╕зр╕в LLM

р╣Гр╕Кр╣Й **ChatGPT / Llama 3 / Gemini**
р╕Кр╣Ир╕зр╕в тАЬр╕кр╕гр╕╕р╕ЫтАЭ р╕лр╕гр╕╖р╕н тАЬр╕нр╕Шр╕┤р╕Ър╕▓р╕втАЭ р╣Ар╕Щр╕╖р╣Йр╕нр╕лр╕▓р╣Бр╕Хр╣Ир╕ер╕░р╕кр╣Ир╕зр╕Щ

```python
prompt = "р╕кр╕гр╕╕р╕Ыр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕Щр╕╡р╣Йр╣Гр╕лр╣Йр╕Щр╕▒р╕Бр╣Ар╕гр╕╡р╕вр╕Щр╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╕Зр╣Ир╕▓р╕в:\n\n" + chunk
```

ЁЯУШ *AI р╕Ир╕░р╕Кр╣Ир╕зр╕вр╕Чр╕│р╣Гр╕лр╣Йр╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Ар╕Вр╣Йр╕▓р╣Гр╕Ир╕Зр╣Ир╕▓р╕вр╕Вр╕╢р╣Йр╕Щ*

---

# ЁЯФв р╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щр╕Чр╕╡р╣И 3: р╣Бр╕Ыр╕ер╕Зр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Ар╕Ыр╣Зр╕Щр╕Хр╕▒р╕зр╣Ар╕ер╕В (Embedding)

AI р╣Ар╕Вр╣Йр╕▓р╣Гр╕И тАЬр╕Др╕зр╕▓р╕бр╕лр╕бр╕▓р╕втАЭ р╕Ьр╣Ир╕▓р╕Щр╕Хр╕▒р╕зр╣Ар╕ер╕В
р╣Ар╕гр╕╡р╕вр╕Бр╕зр╣Ир╕▓ **р╣Ар╕зр╕Бр╣Ар╕Хр╕нр╕гр╣М (Vector)**

```python
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2')
vec = model.encode(["р╕кр╕бр╕нр╕Зр╕Вр╕нр╕Зр╕бр╕Щр╕╕р╕йр╕вр╣М..."])
print(vec[:10])
```

ЁЯзй тАЬр╕Хр╕▒р╕зр╣Ар╕ер╕ВтАЭ р╣Ар╕лр╕ер╣Ир╕▓р╕Щр╕╡р╣Йр╣Бр╕Чр╕Щр╕Др╕зр╕▓р╕бр╕лр╕бр╕▓р╕вр╕Вр╕нр╕Зр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕б

---

# ЁЯТ╛ р╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щр╕Чр╕╡р╣И 4: р╕Др╣Йр╕Щр╕лр╕▓р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Чр╕╡р╣Ир╣Ар╕Бр╕╡р╣Ир╕вр╕зр╕Вр╣Йр╕нр╕З (Retrieval)

```python
from sklearn.metrics.pairwise import cosine_similarity
score = cosine_similarity(query_vec, embeddings)
```

ЁЯУШ *р╕Др╣Ир╕▓р╕Др╕зр╕▓р╕бр╣Гр╕Бр╕ер╣Йр╣Ар╕Др╕╡р╕вр╕Зр╕бр╕▓р╕Б р╣Бр╕Ыр╕ер╕зр╣Ир╕▓р╣Ар╕Щр╕╖р╣Йр╕нр╕лр╕▓р╣Ар╕Бр╕╡р╣Ир╕вр╕зр╕Вр╣Йр╕нр╕Зр╕Бр╕▒р╕Щр╕бр╕▓р╕Б*

---

# ЁЯТм р╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щр╕Чр╕╡р╣И 5: р╣Гр╕лр╣Й AI р╕кр╕гр╣Йр╕▓р╕Зр╕Др╕│р╕Хр╕нр╕Ъ

```python
prompt = f"р╕Хр╕нр╕Ър╕Др╕│р╕Цр╕▓р╕бр╕Щр╕╡р╣Йр╣Вр╕Фр╕вр╕нр╣Йр╕▓р╕Зр╕нр╕┤р╕Зр╕Ир╕▓р╕Бр╕Вр╣Йр╕нр╕бр╕╣р╕е:\n{docs}\nр╕Др╕│р╕Цр╕▓р╕б: {question}"
```

> AI р╕Ир╕░р╕кр╕гр╣Йр╕▓р╕Зр╕Др╕│р╕Хр╕нр╕Ър╕Чр╕╡р╣Ир╕нр╕┤р╕Зр╕Ир╕▓р╕Бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Ир╕гр╕┤р╕З
> р╣Др╕бр╣Ир╣Др╕Фр╣Й тАЬр╣Ар╕Фр╕▓тАЭ р╕Ир╕▓р╕Бр╕Др╕зр╕▓р╕бр╕Ир╕│р╕Вр╕нр╕Зр╣Вр╕бр╣Ар╕Фр╕е

---

# ЁЯдЦ р╣Ар╕гр╕▓р╣Др╕Фр╣Йр╕гр╕░р╕Ър╕Ъ RAG р╣Бр╕Ър╕Ър╕Зр╣Ир╕▓р╕вр╣Бр╕ер╣Йр╕з!

ЁЯзй р╕кр╕гр╕╕р╕Ыр╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щр╕Чр╕▒р╣Йр╕Зр╕лр╕бр╕Ф

1я╕ПтГг р╣Бр╕Ър╣Ир╕Зр╣Ар╕нр╕Бр╕кр╕▓р╕гр╣Ар╕Ыр╣Зр╕Щр╕Кр╕┤р╣Йр╕Щр╣Ар╕ер╣Зр╕Б р╣Ж
2я╕ПтГг р╣Гр╕лр╣Й AI р╕кр╕гр╕╕р╕Ыр╕лр╕гр╕╖р╕нр╣Ар╕кр╕гр╕┤р╕бр╕Ър╕гр╕┤р╕Ър╕Ч
3я╕ПтГг р╣Бр╕Ыр╕ер╕Зр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Ар╕Ыр╣Зр╕Щр╣Ар╕зр╕Бр╣Ар╕Хр╕нр╕гр╣М
4я╕ПтГг р╕Др╣Йр╕Щр╕лр╕▓р╕кр╣Ир╕зр╕Щр╕Чр╕╡р╣Ир╣Гр╕Бр╕ер╣Йр╣Ар╕Др╕╡р╕вр╕Зр╕Бр╕▒р╕Ър╕Др╕│р╕Цр╕▓р╕б
5я╕ПтГг р╣Гр╕лр╣Й AI р╕кр╕гр╣Йр╕▓р╕Зр╕Др╕│р╕Хр╕нр╕Ър╣Гр╕лр╕бр╣И

---

# ЁЯОо Workshop Activity

### ЁЯФ╣ р╕Чр╕Фр╕ер╕нр╕Зр╕Ир╕гр╕┤р╕Зр╣Гр╕Щ Google Colab

1. р╣Ар╕Ыр╕┤р╕Фр╣Др╕Яр╕ер╣М `RAG_Workshop.ipynb`
2. р╕Др╕▒р╕Фр╕ер╕нр╕Бр╣Вр╕Др╣Йр╕Фр╣Бр╕Хр╣Ир╕ер╕░р╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щ
3. р╕Юр╕┤р╕бр╕Юр╣Мр╕Др╕│р╕Цр╕▓р╕бр╣Ар╕Кр╣Ир╕Щ

   * тАЬр╕бр╕Щр╕╕р╕йр╕вр╣Мр╕Др╕┤р╕Фр╣Др╕Фр╣Йр╕нр╕вр╣Ир╕▓р╕Зр╣Др╕г?тАЭ
   * тАЬр╕гр╕░р╕Ър╕Ър╕Ыр╕гр╕░р╕кр╕▓р╕Чр╕Др╕╖р╕нр╕нр╕░р╣Др╕г?тАЭ
4. р╕Фр╕╣р╕зр╣Ир╕▓ AI р╕Хр╕нр╕Ър╕нр╕вр╣Ир╕▓р╕Зр╣Др╕г

---

# ЁЯзй Workshop Challenge

> р╕кр╕гр╣Йр╕▓р╕З тАЬAI р╕Ьр╕╣р╣Йр╕Кр╣Ир╕зр╕вр╕нр╣Ир╕▓р╕Щр╕лр╕Щр╕▒р╕Зр╕кр╕╖р╕нр╣Ар╕гр╕╡р╕вр╕ЩтАЭ р╕Вр╕нр╕Зр╕Др╕╕р╕Ур╣Ар╕нр╕З

### р╕Хр╕▒р╕зр╕нр╕вр╣Ир╕▓р╕З:

* ЁЯУШ р╕кр╕гр╕╕р╕Ыр╣Ар╕Щр╕╖р╣Йр╕нр╕лр╕▓р╕зр╕┤р╕Чр╕вр╕▓р╕ир╕▓р╕кр╕Хр╕гр╣М р╕Ър╕Ч 1
* ЁЯУЧ р╕кр╕гр╕╕р╕Ыр╕Ыр╕гр╕░р╕зр╕▒р╕Хр╕┤р╕ир╕▓р╕кр╕Хр╕гр╣Мр╕Кр╕▓р╕Хр╕┤р╣Др╕Чр╕в
* ЁЯУЩ р╕кр╕гр╕╕р╕Ыр╕кр╕▓р╕гр╕░р╕Ир╕▓р╕Бр╕Ър╕Чр╣Ар╕гр╕╡р╕вр╕Щр╕Др╕Ур╕┤р╕Хр╕ир╕▓р╕кр╕Хр╕гр╣М

---

# ЁЯзн р╕кр╕гр╕╕р╕Ыр╕кр╕┤р╣Ир╕Зр╕Чр╕╡р╣Ир╣Ар╕гр╕╡р╕вр╕Щр╕гр╕╣р╣Йр╕зр╕▒р╕Щр╕Щр╕╡р╣Й

| р╕Вр╕▒р╣Йр╕Щр╕Хр╕нр╕Щ    | р╕Др╕зр╕▓р╕бр╕лр╕бр╕▓р╕в                    |
| ---------- | --------------------------- |
| Chunking   | р╣Бр╕Ър╣Ир╕Зр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕нр╕нр╕Бр╣Ар╕Ыр╣Зр╕Щр╕кр╣Ир╕зр╕Щр╕вр╣Ир╕нр╕в  |
| Context    | р╣Гр╕лр╣Й AI р╕кр╕гр╕╕р╕Ыр╣Ар╕Щр╕╖р╣Йр╕нр╕лр╕▓р╣Бр╕Хр╣Ир╕ер╕░р╕кр╣Ир╕зр╕Щ |
| Embedding  | р╣Бр╕Ыр╕ер╕Зр╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╣Ар╕Ыр╣Зр╕Щр╕Хр╕▒р╕зр╣Ар╕ер╕В       |
| Retrieval  | р╕Др╣Йр╕Щр╕лр╕▓р╕Вр╣Йр╕нр╕Др╕зр╕▓р╕бр╕Чр╕╡р╣Ир╣Ар╕Бр╕╡р╣Ир╕вр╕зр╕Вр╣Йр╕нр╕З   |
| Generation | р╕кр╕гр╣Йр╕▓р╕Зр╕Др╕│р╕Хр╕нр╕Ър╕Ир╕▓р╕Бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Ир╕гр╕┤р╕З     |

---

# ЁЯТб р╕Цр╕▓р╕бр╕Хр╕▒р╕зр╣Ар╕нр╕Зр╕Фр╕╣р╕кр╕┤тАж

* р╕Цр╣Йр╕▓р╣Ар╕гр╕▓р╕Щр╕│ RAG р╣Др╕Ыр╣Гр╕Кр╣Йр╕Бр╕▒р╕Ъ тАЬр╕Ър╕Чр╣Ар╕гр╕╡р╕вр╕Щр╣Гр╕Щр╕лр╣Йр╕нр╕Зр╣Ар╕гр╕╡р╕вр╕ЩтАЭ р╕Ир╕░р╣Др╕Фр╣Йр╕нр╕░р╣Др╕гр╕Ър╣Йр╕▓р╕З?
* AI р╕Ир╕░р╕Кр╣Ир╕зр╕вр╣Гр╕лр╣Йр╣Ар╕гр╕▓ тАЬр╣Ар╕Вр╣Йр╕▓р╣Гр╕ИтАЭ р╕бр╕▓р╕Бр╕Бр╕зр╣Ир╕▓р╣Бр╕Др╣И тАЬр╕Ир╕│тАЭ р╣Др╕Фр╣Йр╕нр╕вр╣Ир╕▓р╕Зр╣Др╕г?
* р╕Цр╣Йр╕▓р╕нр╕вр╕▓р╕Бр╣Гр╕лр╣Йр╕бр╕▒р╕Щр╕Йр╕ер╕▓р╕Фр╕Вр╕╢р╣Йр╕Щ р╣Ар╕гр╕▓р╕Ир╕░р╣Ар╕Юр╕┤р╣Ир╕бр╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Бр╕Ър╕Ър╣Др╕лр╕Щ?

---

# ЁЯЪА р╕ар╕▓р╕гр╕Бр╕┤р╕Ир╕Хр╣Ир╕нр╕вр╕нр╕Ф (Extension Ideas)

* ЁЯза р╕Чр╕│ RAG р╕Бр╕▒р╕Ъ **р╕лр╕Щр╕▒р╕Зр╕кр╕╖р╕нр╣Ар╕гр╕╡р╕вр╕Щр╕зр╕┤р╕Чр╕вр╕▓р╕ир╕▓р╕кр╕Хр╕гр╣М**
* ЁЯТм р╕Чр╕│ Chatbot р╕кр╕│р╕лр╕гр╕▒р╕Ъ **р╕Хр╕┤р╕зр╕кр╕нр╕Ъ O-NET**
* ЁЯУЪ р╕Чр╕│р╕кр╕гр╕╕р╕Ыр╕Ър╕Чр╣Ар╕гр╕╡р╕вр╕Щр╣Бр╕Ър╕Ър╕нр╕▒р╕Хр╣Вр╕Щр╕бр╕▒р╕Хр╕┤

---

# ЁЯСП р╕кр╕гр╕╕р╕Ы Workshop р╕зр╕▒р╕Щр╕Щр╕╡р╣Й

ЁЯОп р╕Чр╕╕р╕Бр╕Др╕Щр╣Др╕Фр╣Йр╣Ар╕гр╕╡р╕вр╕Щр╕гр╕╣р╣Йр╕зр╣Ир╕▓
AI р╕нр╣Ир╕▓р╕Щр╣Ар╕нр╕Бр╕кр╕▓р╕гр╣Др╕Фр╣Йр╕Фр╣Йр╕зр╕вр╕Бр╕▓р╕г
**тАЬр╕Др╣Йр╕Щр╕лр╕▓ (Retrieve)тАЭ + тАЬр╕кр╕гр╣Йр╕▓р╕Зр╕Др╕│р╕Хр╕нр╕Ъ (Generate)тАЭ**

ЁЯУШ р╕лр╕ер╕▒р╕Бр╕Бр╕▓р╕гр╕Щр╕╡р╣Йр╣Ар╕гр╕╡р╕вр╕Бр╕зр╣Ир╕▓ **RAG Framework**
р╣Бр╕ер╕░р╣Ар╕Ыр╣Зр╕Щр╕Юр╕╖р╣Йр╕Щр╕Рр╕▓р╕Щр╕Вр╕нр╕З ChatGPT, Gemini, р╣Бр╕ер╕░ Copilot

---

# ЁЯзСтАНЁЯТ╗ р╕кр╕гр╣Йр╕▓р╕З AI р╕Ьр╕╣р╣Йр╕Кр╣Ир╕зр╕вр╕Вр╕нр╕Зр╕Др╕╕р╕Ур╣Ар╕нр╕З!

> тАЬр╕Хр╣Ир╕нр╣Др╕Ыр╕Щр╕╡р╣Й р╣Ар╕зр╕ер╕▓р╕нр╣Ир╕▓р╕Щр╕лр╕Щр╕▒р╕Зр╕кр╕╖р╕нр╕кр╕нр╕Ъ
> р╕Др╕╕р╕Ур╣Др╕бр╣Ир╕Хр╣Йр╕нр╕Зр╕нр╣Ир╕▓р╕Щр╕Др╕Щр╣Ар╕Фр╕╡р╕вр╕зр╕нр╕╡р╕Бр╕Хр╣Ир╕нр╣Др╕ЫтАЭ

ЁЯМЯ р╕Вр╕нр╕Ър╕Др╕╕р╕Ур╕Щр╕▒р╕Бр╣Ар╕гр╕╡р╕вр╕Щр╕Чр╕╕р╕Бр╕Др╕Щр╕Чр╕╡р╣Ир╕гр╣Ир╕зр╕б Workshop
ЁЯСитАНЁЯПл р╕Кр╕Щр╕▒р╕Щр╕Чр╣Мр╕Бр╕гр╕Ур╣М  р╕Ир╕▒р╕Щр╣Бр╕Фр╕З тАУ Walailak University


